2024-12-26 18:50:24,968 INFO: Flask app started [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/run.py:18]
2024-12-26 18:50:25,006 INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.186:8000 [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 18:50:25,006 INFO: [33mPress CTRL+C to quit[0m [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 18:50:44,305 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 83, in process_whatsapp_message
    from app.services.openai_service import generate_response  # Add this import
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 6, in <module>
    from backend.graph import graph_runnable
ModuleNotFoundError: No module named 'backend'
2024-12-26 18:50:44,311 INFO: 127.0.0.1 - - [26/Dec/2024 18:50:44] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 18:50:44,972 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 83, in process_whatsapp_message
    from app.services.openai_service import generate_response  # Add this import
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 6, in <module>
    from backend.graph import graph_runnable
ModuleNotFoundError: No module named 'backend'
2024-12-26 18:50:44,974 INFO: 127.0.0.1 - - [26/Dec/2024 18:50:44] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 18:50:45,938 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 83, in process_whatsapp_message
    from app.services.openai_service import generate_response  # Add this import
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 6, in <module>
    from backend.graph import graph_runnable
ModuleNotFoundError: No module named 'backend'
2024-12-26 18:50:45,939 INFO: 127.0.0.1 - - [26/Dec/2024 18:50:45] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 18:50:48,197 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 83, in process_whatsapp_message
    from app.services.openai_service import generate_response  # Add this import
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 6, in <module>
    from backend.graph import graph_runnable
ModuleNotFoundError: No module named 'backend'
2024-12-26 18:50:48,199 INFO: 127.0.0.1 - - [26/Dec/2024 18:50:48] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 18:51:11,058 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 83, in process_whatsapp_message
    from app.services.openai_service import generate_response  # Add this import
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 6, in <module>
    from backend.graph import graph_runnable
ModuleNotFoundError: No module named 'backend'
2024-12-26 18:51:11,059 INFO: 127.0.0.1 - - [26/Dec/2024 18:51:11] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 18:53:40,540 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 83, in process_whatsapp_message
    from app.services.openai_service import generate_response  # Add this import
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 6, in <module>
    from backend.graph import graph_runnable
ModuleNotFoundError: No module named 'backend'
2024-12-26 18:53:40,568 INFO: 127.0.0.1 - - [26/Dec/2024 18:53:40] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 18:54:46,868 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 83, in process_whatsapp_message
    from app.services.openai_service import generate_response  # Add this import
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 6, in <module>
    from backend.graph import graph_runnable
ModuleNotFoundError: No module named 'backend'
2024-12-26 18:54:46,871 INFO: 127.0.0.1 - - [26/Dec/2024 18:54:46] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 18:55:58,109 INFO: Flask app started [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/run.py:26]
2024-12-26 18:55:58,158 INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.186:8000 [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 18:55:58,158 INFO: [33mPress CTRL+C to quit[0m [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 18:56:05,892 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 18:56:05,893 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 18:56:05,902 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 18:56:05,902 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 18:56:12,053 INFO: Discovering subpackages in _NamespacePath(['/usr/local/lib/python3.11/site-packages/pinecone_plugins']) [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_namespace_packages.py:12]
2024-12-26 18:56:12,054 INFO: Looking for plugins in pinecone_plugins.inference [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_plugins.py:9]
2024-12-26 18:56:12,084 INFO: Installing plugin inference into Pinecone [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/installation.py:10]
2024-12-26 18:56:12,417 DEBUG: response body: b'{"name":"jumbo-ai","metric":"dotproduct","dimension":512,"status":{"ready":true,"state":"Ready"},"host":"jumbo-ai-blg7rf2.svc.aped-4627-b74a.pinecone.io","spec":{"serverless":{"region":"us-east-1","cloud":"aws"}},"deletion_protection":"disabled"}' [in /usr/local/lib/python3.11/site-packages/pinecone/core/openapi/shared/rest.py:264]
2024-12-26 18:56:12,541 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 18:56:12,542 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 18:56:12,554 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 18:56:12,554 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 18:56:14,705 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 28, in generate_response
    save_message(wa_id, "user", message_body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/backend/db.py", line 219, in save_message
    cur.execute("""
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type uuid: "5491149276686"
L√çNEA 3:                 VALUES ('5491149276686', 'user', 'hola', '20...
                                 ^

2024-12-26 18:56:14,708 INFO: 127.0.0.1 - - [26/Dec/2024 18:56:14] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 18:56:15,624 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 28, in generate_response
    save_message(wa_id, "user", message_body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/backend/db.py", line 219, in save_message
    cur.execute("""
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type uuid: "5491149276686"
L√çNEA 3:                 VALUES ('5491149276686', 'user', 'hola', '20...
                                 ^

2024-12-26 18:56:15,627 INFO: 127.0.0.1 - - [26/Dec/2024 18:56:15] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 18:56:16,647 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 28, in generate_response
    save_message(wa_id, "user", message_body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/backend/db.py", line 219, in save_message
    cur.execute("""
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type uuid: "5491149276686"
L√çNEA 3:                 VALUES ('5491149276686', 'user', 'hola', '20...
                                 ^

2024-12-26 18:56:16,649 INFO: 127.0.0.1 - - [26/Dec/2024 18:56:16] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 18:56:18,908 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 28, in generate_response
    save_message(wa_id, "user", message_body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/backend/db.py", line 219, in save_message
    cur.execute("""
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type uuid: "5491149276686"
L√çNEA 3:                 VALUES ('5491149276686', 'user', 'hola', '20...
                                 ^

2024-12-26 18:56:18,911 INFO: 127.0.0.1 - - [26/Dec/2024 18:56:18] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 18:56:43,998 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 28, in generate_response
    save_message(wa_id, "user", message_body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/backend/db.py", line 219, in save_message
    cur.execute("""
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type uuid: "5491149276686"
L√çNEA 3:                 VALUES ('5491149276686', 'user', 'hola', '20...
                                 ^

2024-12-26 18:56:44,002 INFO: 127.0.0.1 - - [26/Dec/2024 18:56:44] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 18:57:45,130 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 28, in generate_response
    save_message(wa_id, "user", message_body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/backend/db.py", line 219, in save_message
    cur.execute("""
psycopg2.errors.InvalidTextRepresentation: invalid input syntax for type uuid: "5491149276686"
L√çNEA 3:                 VALUES ('5491149276686', 'user', 'hello', '2...
                                 ^

2024-12-26 18:57:45,141 INFO: 127.0.0.1 - - [26/Dec/2024 18:57:45] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:00:23,852 INFO: Flask app started [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/run.py:26]
2024-12-26 19:00:23,894 INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.186:8000 [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:00:23,894 INFO: [33mPress CTRL+C to quit[0m [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:00:36,548 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:00:36,549 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:00:36,563 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:00:36,564 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:00:42,462 INFO: Discovering subpackages in _NamespacePath(['/usr/local/lib/python3.11/site-packages/pinecone_plugins']) [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_namespace_packages.py:12]
2024-12-26 19:00:42,463 INFO: Looking for plugins in pinecone_plugins.inference [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_plugins.py:9]
2024-12-26 19:00:42,486 INFO: Installing plugin inference into Pinecone [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/installation.py:10]
2024-12-26 19:00:44,105 DEBUG: response body: b'{"name":"jumbo-ai","metric":"dotproduct","dimension":512,"status":{"ready":true,"state":"Ready"},"host":"jumbo-ai-blg7rf2.svc.aped-4627-b74a.pinecone.io","spec":{"serverless":{"region":"us-east-1","cloud":"aws"}},"deletion_protection":"disabled"}' [in /usr/local/lib/python3.11/site-packages/pinecone/core/openapi/shared/rest.py:264]
2024-12-26 19:00:44,212 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:00:44,213 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:00:44,221 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:00:44,221 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:00:48,530 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 49, in generate_response
    response = invoke_our_graph(state)
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 14, in invoke_our_graph
    for event in graph_runnable.stream_events(state, version="v2"):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'CompiledStateGraph' object has no attribute 'stream_events'
2024-12-26 19:00:48,533 INFO: 127.0.0.1 - - [26/Dec/2024 19:00:48] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:00:50,727 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 49, in generate_response
    response = invoke_our_graph(state)
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 14, in invoke_our_graph
    for event in graph_runnable.stream_events(state, version="v2"):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'CompiledStateGraph' object has no attribute 'stream_events'
2024-12-26 19:00:50,731 INFO: 127.0.0.1 - - [26/Dec/2024 19:00:50] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:00:52,934 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 49, in generate_response
    response = invoke_our_graph(state)
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 14, in invoke_our_graph
    for event in graph_runnable.stream_events(state, version="v2"):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'CompiledStateGraph' object has no attribute 'stream_events'
2024-12-26 19:00:52,937 INFO: 127.0.0.1 - - [26/Dec/2024 19:00:52] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:00:56,618 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 49, in generate_response
    response = invoke_our_graph(state)
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 14, in invoke_our_graph
    for event in graph_runnable.stream_events(state, version="v2"):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'CompiledStateGraph' object has no attribute 'stream_events'
2024-12-26 19:00:56,623 INFO: 127.0.0.1 - - [26/Dec/2024 19:00:56] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:01:23,982 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 49, in generate_response
    response = invoke_our_graph(state)
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 14, in invoke_our_graph
    for event in graph_runnable.stream_events(state, version="v2"):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'CompiledStateGraph' object has no attribute 'stream_events'
2024-12-26 19:01:23,985 INFO: 127.0.0.1 - - [26/Dec/2024 19:01:23] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:02:25,749 INFO: Flask app started [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/run.py:26]
2024-12-26 19:02:25,793 INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.186:8000 [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:02:25,793 INFO: [33mPress CTRL+C to quit[0m [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:02:33,631 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:33,631 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:33,641 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:33,642 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:38,616 INFO: Discovering subpackages in _NamespacePath(['/usr/local/lib/python3.11/site-packages/pinecone_plugins']) [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_namespace_packages.py:12]
2024-12-26 19:02:38,616 INFO: Looking for plugins in pinecone_plugins.inference [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_plugins.py:9]
2024-12-26 19:02:38,635 INFO: Installing plugin inference into Pinecone [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/installation.py:10]
2024-12-26 19:02:39,164 DEBUG: response body: b'{"name":"jumbo-ai","metric":"dotproduct","dimension":512,"status":{"ready":true,"state":"Ready"},"host":"jumbo-ai-blg7rf2.svc.aped-4627-b74a.pinecone.io","spec":{"serverless":{"region":"us-east-1","cloud":"aws"}},"deletion_protection":"disabled"}' [in /usr/local/lib/python3.11/site-packages/pinecone/core/openapi/shared/rest.py:264]
2024-12-26 19:02:39,241 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:39,241 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:39,250 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:39,250 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:42,926 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:42,927 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:42,938 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:42,938 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:42,958 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:02:42,960 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:02:42,962 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:43,065 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x128ed7ad0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:43,066 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x129292e70> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:43,142 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12922f850> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:43,142 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:43,143 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:43,144 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:43,144 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:43,144 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:44,014 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:02:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'357'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_f92cd2102d14bc5c6972f0f0344b6ab6'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=FAYkgev3TMB8f63LRRJ9QukJTGBXpGxL9xrM0so64as-1735250564-1.0.1.1-Los0JRr9z90T6uDFnnxcFtkay5e7AYHtxz9W_sR525NPB9Gjef.HOaTi3ZNOAEH0Ly.4revX5.sx6E3x1.291A; path=/; expires=Thu, 26-Dec-24 22:32:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=ihCixHGR4owKZoJNE9W.e4nr1qC5CBu7GxRMK.v_3W0-1735250564246-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f845b555c189b23-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:44,019 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:02:44,021 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:44,022 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:44,022 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:44,022 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:44,023 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:02:44 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '357'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199678'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '96ms'), ('x-request-id', 'req_f92cd2102d14bc5c6972f0f0344b6ab6'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=FAYkgev3TMB8f63LRRJ9QukJTGBXpGxL9xrM0so64as-1735250564-1.0.1.1-Los0JRr9z90T6uDFnnxcFtkay5e7AYHtxz9W_sR525NPB9Gjef.HOaTi3ZNOAEH0Ly.4revX5.sx6E3x1.291A; path=/; expires=Thu, 26-Dec-24 22:32:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=ihCixHGR4owKZoJNE9W.e4nr1qC5CBu7GxRMK.v_3W0-1735250564246-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f845b555c189b23-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:02:44,023 DEBUG: request_id: req_f92cd2102d14bc5c6972f0f0344b6ab6 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:02:44,053 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:44,054 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:44,064 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:44,064 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:44,085 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:02:44,086 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:02:44,086 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:44,105 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x128f8fbd0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:44,105 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x129292b10> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:44,141 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12937c090> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:44,142 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:44,143 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:44,143 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:44,144 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:44,145 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:45,861 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:02:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'1159'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199551'), (b'x-ratelimit-reset-requests', b'16.263s'), (b'x-ratelimit-reset-tokens', b'134ms'), (b'x-request-id', b'req_bb6e2ab19f30f9f3a94ef14ba7b0e1b1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=n04Bj9_MlOgnQ8.XD_mAJ6OaKE6tvDAKrVakFmEO0j0-1735250566-1.0.1.1-cVkNjedILu4itabHM5_AX4RuYZ7w0Ksk6skZaUjqD.wf57sRxAG0MOKL2w.MN3O8.DAl9Yt9071OuwtZkC9ncA; path=/; expires=Thu, 26-Dec-24 22:32:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=8HQTFZ9Kkvrr3TjS9S6IzZTZcuhvLqg4WiGPtZ8Y6zk-1735250566062-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f845b5b8bd69b24-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:45,862 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:02:45,863 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:45,864 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:45,864 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:45,864 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:45,865 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:02:46 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '1159'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9998'), ('x-ratelimit-remaining-tokens', '199551'), ('x-ratelimit-reset-requests', '16.263s'), ('x-ratelimit-reset-tokens', '134ms'), ('x-request-id', 'req_bb6e2ab19f30f9f3a94ef14ba7b0e1b1'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=n04Bj9_MlOgnQ8.XD_mAJ6OaKE6tvDAKrVakFmEO0j0-1735250566-1.0.1.1-cVkNjedILu4itabHM5_AX4RuYZ7w0Ksk6skZaUjqD.wf57sRxAG0MOKL2w.MN3O8.DAl9Yt9071OuwtZkC9ncA; path=/; expires=Thu, 26-Dec-24 22:32:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=8HQTFZ9Kkvrr3TjS9S6IzZTZcuhvLqg4WiGPtZ8Y6zk-1735250566062-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f845b5b8bd69b24-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:02:45,865 DEBUG: request_id: req_bb6e2ab19f30f9f3a94ef14ba7b0e1b1 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:02:45,875 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 58, in generate_response
    new_message = response["messages"].content
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'content'
2024-12-26 19:02:45,878 INFO: 127.0.0.1 - - [26/Dec/2024 19:02:45] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:02:48,317 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:48,318 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:48,332 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:48,332 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:48,348 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:02:48,349 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:02:48,349 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:48,393 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x128f07a90> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:48,393 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x1292929f0> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:48,449 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x124cb5390> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:48,449 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:48,450 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:48,450 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:48,450 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:48,451 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:48,949 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:02:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'311'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'20.93s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_d956c86652b3ad81b8d951c4a83f3524'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=T1t78oynL081.24Q7LR.7G2uD5mNuhnUJh9oroygqGw-1735250569-1.0.1.1-cb9DR5Lq8SmCg673cBifQ9et.agzDNlDKhWrMcFAamuzRAp3Ggr6ljYZosMP2Pj1tl1NnpYNPmRFovsQX9IdtA; path=/; expires=Thu, 26-Dec-24 22:32:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=wN3uGiytl4jZDeBFjz9gWJn.V.KySP8vREjyhPtxqlg-1735250569176-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f845b767ed1e7a8-SCL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:48,950 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:02:48,950 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:48,953 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:48,953 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:48,953 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:48,953 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:02:49 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '311'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9997'), ('x-ratelimit-remaining-tokens', '199678'), ('x-ratelimit-reset-requests', '20.93s'), ('x-ratelimit-reset-tokens', '96ms'), ('x-request-id', 'req_d956c86652b3ad81b8d951c4a83f3524'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=T1t78oynL081.24Q7LR.7G2uD5mNuhnUJh9oroygqGw-1735250569-1.0.1.1-cb9DR5Lq8SmCg673cBifQ9et.agzDNlDKhWrMcFAamuzRAp3Ggr6ljYZosMP2Pj1tl1NnpYNPmRFovsQX9IdtA; path=/; expires=Thu, 26-Dec-24 22:32:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=wN3uGiytl4jZDeBFjz9gWJn.V.KySP8vREjyhPtxqlg-1735250569176-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f845b767ed1e7a8-SCL'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:02:48,953 DEBUG: request_id: req_d956c86652b3ad81b8d951c4a83f3524 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:02:48,957 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:48,957 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:48,966 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:48,967 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:48,987 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:02:48,988 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:02:48,988 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:49,016 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1293ce150> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:49,016 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x1292928d0> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:49,062 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12937d950> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:49,062 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:49,063 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:49,063 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:49,063 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:49,063 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:51,022 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:02:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'1724'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'199550'), (b'x-ratelimit-reset-requests', b'28.938s'), (b'x-ratelimit-reset-tokens', b'135ms'), (b'x-request-id', b'req_437ee87037d8ba0180b360a1b309b1ea'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=h0eQY10h0w9Lhh1bGm_OrpTbqhdvx6boak.2.hF.xiw-1735250571-1.0.1.1-nCyPfLENIN8G8bF4ZYbNu4bT82aBLE1014pzL3lU6oBG2MSQS6v.c5JkZNNlIbSqApVc3T45TjPpzJNtV7Ah9A; path=/; expires=Thu, 26-Dec-24 22:32:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=9x.bkFNOe_JTHYsWsNRvSauhCygpXPXPog6FLt9qs3w-1735250571258-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f845b7a49151feb-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:51,024 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:02:51,024 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:51,025 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:51,025 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:51,026 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:51,026 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:02:51 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '1724'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9996'), ('x-ratelimit-remaining-tokens', '199550'), ('x-ratelimit-reset-requests', '28.938s'), ('x-ratelimit-reset-tokens', '135ms'), ('x-request-id', 'req_437ee87037d8ba0180b360a1b309b1ea'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=h0eQY10h0w9Lhh1bGm_OrpTbqhdvx6boak.2.hF.xiw-1735250571-1.0.1.1-nCyPfLENIN8G8bF4ZYbNu4bT82aBLE1014pzL3lU6oBG2MSQS6v.c5JkZNNlIbSqApVc3T45TjPpzJNtV7Ah9A; path=/; expires=Thu, 26-Dec-24 22:32:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=9x.bkFNOe_JTHYsWsNRvSauhCygpXPXPog6FLt9qs3w-1735250571258-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f845b7a49151feb-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:02:51,027 DEBUG: request_id: req_437ee87037d8ba0180b360a1b309b1ea [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:02:51,036 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 58, in generate_response
    new_message = response["messages"].content
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'content'
2024-12-26 19:02:51,037 INFO: 127.0.0.1 - - [26/Dec/2024 19:02:51] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:02:53,657 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:53,657 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:53,673 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:53,673 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:53,674 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:53,674 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:53,674 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:53,674 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:53,685 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:53,685 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:53,702 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:02:53,703 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:02:53,703 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:53,745 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x128f181d0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:53,745 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x129293650> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:53,790 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12922c910> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:53,790 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:53,790 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:53,791 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:53,791 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:53,791 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:54,356 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:02:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'370'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'32.871s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_2decd4258c255fd140c377d4670c6440'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PWZ88dSZY0MO0IJAXaRfjXt8Lbck0Gp7FfN8fONvOjU-1735250574-1.0.1.1-Ih2cc6tMKi1DBNB213w_vi_.eM9_59IEGHwWdDwrlfpYtLG82cJIa6BmpitIotH9zvxM8vbjtss9UO3BRb7.qA; path=/; expires=Thu, 26-Dec-24 22:32:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=djE9idrq95GOWqwzzAwGYD5tTcuChbdL56Hgs2XVGZI-1735250574577-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f845b97dbb4e7a5-SCL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:54,357 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:02:54,358 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:54,359 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:54,359 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:54,359 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:54,360 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:02:54 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '370'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9996'), ('x-ratelimit-remaining-tokens', '199678'), ('x-ratelimit-reset-requests', '32.871s'), ('x-ratelimit-reset-tokens', '96ms'), ('x-request-id', 'req_2decd4258c255fd140c377d4670c6440'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=PWZ88dSZY0MO0IJAXaRfjXt8Lbck0Gp7FfN8fONvOjU-1735250574-1.0.1.1-Ih2cc6tMKi1DBNB213w_vi_.eM9_59IEGHwWdDwrlfpYtLG82cJIa6BmpitIotH9zvxM8vbjtss9UO3BRb7.qA; path=/; expires=Thu, 26-Dec-24 22:32:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=djE9idrq95GOWqwzzAwGYD5tTcuChbdL56Hgs2XVGZI-1735250574577-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f845b97dbb4e7a5-SCL'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:02:54,360 DEBUG: request_id: req_2decd4258c255fd140c377d4670c6440 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:02:54,368 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:54,369 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:54,381 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:54,381 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:54,404 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:02:54,405 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:02:54,405 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:54,448 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12937f3d0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:54,448 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x129293380> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:54,473 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1292c09d0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:54,473 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:54,473 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:54,473 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:54,474 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:54,474 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:55,879 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:02:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'1155'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9995'), (b'x-ratelimit-remaining-tokens', b'199548'), (b'x-ratelimit-reset-requests', b'40.816s'), (b'x-ratelimit-reset-tokens', b'135ms'), (b'x-request-id', b'req_e7f1e62ee47e64cca058fa46a3a5f67c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Cdgj_xZTRHT03NhWHSMQw8QkUeGmYdNHFYNYGnJPOSw-1735250576-1.0.1.1-G8JBLIQkLuHgAi7dIgB9c96fPpE0hMdr93RqFz9gq3Sf5PF6z_GS68KOMPaBBFGXpHS9fiyGu3uh3_GyIzUkHQ; path=/; expires=Thu, 26-Dec-24 22:32:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=WKsPZqg3xnsdBMUR3t_RfcU_ldaNjBrH4_DR7FhNyus-1735250576076-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f845b9c08829b20-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:55,881 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:02:55,881 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:55,882 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:55,882 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:55,882 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:55,883 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:02:56 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '1155'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9995'), ('x-ratelimit-remaining-tokens', '199548'), ('x-ratelimit-reset-requests', '40.816s'), ('x-ratelimit-reset-tokens', '135ms'), ('x-request-id', 'req_e7f1e62ee47e64cca058fa46a3a5f67c'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Cdgj_xZTRHT03NhWHSMQw8QkUeGmYdNHFYNYGnJPOSw-1735250576-1.0.1.1-G8JBLIQkLuHgAi7dIgB9c96fPpE0hMdr93RqFz9gq3Sf5PF6z_GS68KOMPaBBFGXpHS9fiyGu3uh3_GyIzUkHQ; path=/; expires=Thu, 26-Dec-24 22:32:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=WKsPZqg3xnsdBMUR3t_RfcU_ldaNjBrH4_DR7FhNyus-1735250576076-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f845b9c08829b20-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:02:55,883 DEBUG: request_id: req_e7f1e62ee47e64cca058fa46a3a5f67c [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:02:55,889 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 58, in generate_response
    new_message = response["messages"].content
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'content'
2024-12-26 19:02:55,890 INFO: 127.0.0.1 - - [26/Dec/2024 19:02:55] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:02:59,660 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:59,661 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:59,676 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:02:59,677 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:02:59,692 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:02:59,692 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:02:59,693 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:59,798 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1293cfa10> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:59,798 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x129293140> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:59,925 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12929f010> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:59,925 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:59,926 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:59,926 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:59,926 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:02:59,926 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:00,776 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:03:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'609'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'43.97s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_8e992e6b0ebed67aa9f7f4fd947ce794'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=bq8zGcAiytmIXzF.TaQXkt4Bl8A7RNNg6mpOEVBuXuM-1735250581-1.0.1.1-fWJLctuJxx3LfTTqDQJN5YWuhACOwv1B2B_DHD8msE95703KvAQOBVdCOaZZ82dZvrjqirpyxJDtMabka7C8Fg; path=/; expires=Thu, 26-Dec-24 22:33:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=.eFb0SzAx8MHiF_PqIkToEwCbHPFgGbvVszP0qN8WC4-1735250581010-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f845bbe5be29b1e-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:00,777 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:03:00,777 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:00,778 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:00,778 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:00,778 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:00,778 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:03:01 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '609'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9994'), ('x-ratelimit-remaining-tokens', '199678'), ('x-ratelimit-reset-requests', '43.97s'), ('x-ratelimit-reset-tokens', '96ms'), ('x-request-id', 'req_8e992e6b0ebed67aa9f7f4fd947ce794'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=bq8zGcAiytmIXzF.TaQXkt4Bl8A7RNNg6mpOEVBuXuM-1735250581-1.0.1.1-fWJLctuJxx3LfTTqDQJN5YWuhACOwv1B2B_DHD8msE95703KvAQOBVdCOaZZ82dZvrjqirpyxJDtMabka7C8Fg; path=/; expires=Thu, 26-Dec-24 22:33:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=.eFb0SzAx8MHiF_PqIkToEwCbHPFgGbvVszP0qN8WC4-1735250581010-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f845bbe5be29b1e-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:03:00,779 DEBUG: request_id: req_8e992e6b0ebed67aa9f7f4fd947ce794 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:03:00,785 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:03:00,785 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:03:00,796 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:03:00,796 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:03:00,819 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:03:00,820 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:03:00,820 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:00,878 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x129b93a50> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:00,878 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x129293530> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:01,064 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x129b8bb50> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:01,064 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:01,064 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:01,065 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:01,065 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:01,065 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:02,540 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:03:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'865'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'199547'), (b'x-ratelimit-reset-requests', b'51.211s'), (b'x-ratelimit-reset-tokens', b'135ms'), (b'x-request-id', b'req_f20bc0a857029c9c6ef18d76df16ada5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=M.p0nUY0A2Uli88yuGllMXH2DHRA4m9p3y_68CeQOFo-1735250582-1.0.1.1-LRpUNXM09jjDSWV98A0ZJUD.fmAfoSpbgTtgZHRZzsEaCWsATFCcp.GiC1MlRrvQRusDUNCvg4Ao.NloUGSihA; path=/; expires=Thu, 26-Dec-24 22:33:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=k3wQ9P1oqDF_lulXYYd2clPzOZZ7K6FwkKua0IFS8HI-1735250582665-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f845bc54e169b1e-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:02,541 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:03:02,542 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:02,542 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:02,543 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:02,543 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:02,543 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:03:02 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '865'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9994'), ('x-ratelimit-remaining-tokens', '199547'), ('x-ratelimit-reset-requests', '51.211s'), ('x-ratelimit-reset-tokens', '135ms'), ('x-request-id', 'req_f20bc0a857029c9c6ef18d76df16ada5'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=M.p0nUY0A2Uli88yuGllMXH2DHRA4m9p3y_68CeQOFo-1735250582-1.0.1.1-LRpUNXM09jjDSWV98A0ZJUD.fmAfoSpbgTtgZHRZzsEaCWsATFCcp.GiC1MlRrvQRusDUNCvg4Ao.NloUGSihA; path=/; expires=Thu, 26-Dec-24 22:33:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=k3wQ9P1oqDF_lulXYYd2clPzOZZ7K6FwkKua0IFS8HI-1735250582665-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f845bc54e169b1e-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:03:02,544 DEBUG: request_id: req_f20bc0a857029c9c6ef18d76df16ada5 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:03:02,555 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 58, in generate_response
    new_message = response["messages"].content
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'content'
2024-12-26 19:03:02,556 INFO: 127.0.0.1 - - [26/Dec/2024 19:03:02] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:03:19,295 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:03:19,297 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:03:19,314 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:03:19,315 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:03:19,332 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:03:19,333 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:03:19,333 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:19,353 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x129baaa50> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:19,353 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x129293ec0> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:19,382 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x129baab10> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:19,382 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:19,383 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:19,383 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:19,384 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:19,384 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,076 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:03:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'414'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9995'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'41.754s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_1128fe76ffd97bfe5f43849503c2fccb'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=hy_ZPogYJwsCbqhUxqEA7DunDSFdmkLzAlIZxCHJB9E-1735250600-1.0.1.1-ZKw6ay6jcDmEKVt445IFD0Tz4J8Clash0lfX.S2c6JmBvRSFKgMgC0oqHLwbxLop.Klqu.JPiorowWJvWDNxWg; path=/; expires=Thu, 26-Dec-24 22:33:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=umtB5OH0dbzrT_AAvLmNdAGIdZq4yPRfGU1fAh7VRPY-1735250600312-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f845c37b8f19c0b-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,078 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:03:20,078 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,080 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,080 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,081 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,081 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:03:20 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '414'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9995'), ('x-ratelimit-remaining-tokens', '199678'), ('x-ratelimit-reset-requests', '41.754s'), ('x-ratelimit-reset-tokens', '96ms'), ('x-request-id', 'req_1128fe76ffd97bfe5f43849503c2fccb'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=hy_ZPogYJwsCbqhUxqEA7DunDSFdmkLzAlIZxCHJB9E-1735250600-1.0.1.1-ZKw6ay6jcDmEKVt445IFD0Tz4J8Clash0lfX.S2c6JmBvRSFKgMgC0oqHLwbxLop.Klqu.JPiorowWJvWDNxWg; path=/; expires=Thu, 26-Dec-24 22:33:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=umtB5OH0dbzrT_AAvLmNdAGIdZq4yPRfGU1fAh7VRPY-1735250600312-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f845c37b8f19c0b-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:03:20,082 DEBUG: request_id: req_1128fe76ffd97bfe5f43849503c2fccb [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:03:20,089 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:03:20,090 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:03:20,105 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:03:20,106 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:03:20,117 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,117 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,117 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,118 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,118 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,118 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,118 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,118 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,141 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:03:20,142 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:03:20,142 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,190 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x128eed050> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,190 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x129292b10> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,256 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1292ea9d0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,256 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,257 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,257 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,257 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:20,257 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:21,483 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:03:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'878'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'199545'), (b'x-ratelimit-reset-requests', b'49.559s'), (b'x-ratelimit-reset-tokens', b'136ms'), (b'x-request-id', b'req_465cd217c91839b390fd96314394b3f6'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dTvz5XNBYLLZ9wpAxxxRM1juzhppsNtHatJNNXfOpjM-1735250601-1.0.1.1-fuXoz4X.S5MNE9V0LHNFIu4w1JZ4x_9PgeLC8m.dW70BEf.Z9b3NnHouyWeQqfq.RhZ_dS7q.hczluFBqK_czg; path=/; expires=Thu, 26-Dec-24 22:33:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=m.7dW_wzZ4v0JnPYRHxUS3.dRiMkD0rkO0bHKRAb2YQ-1735250601592-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f845c3d787ce7a4-SCL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:21,485 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:03:21,485 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:21,486 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:21,487 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:21,487 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:21,487 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:03:21 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '878'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9994'), ('x-ratelimit-remaining-tokens', '199545'), ('x-ratelimit-reset-requests', '49.559s'), ('x-ratelimit-reset-tokens', '136ms'), ('x-request-id', 'req_465cd217c91839b390fd96314394b3f6'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=dTvz5XNBYLLZ9wpAxxxRM1juzhppsNtHatJNNXfOpjM-1735250601-1.0.1.1-fuXoz4X.S5MNE9V0LHNFIu4w1JZ4x_9PgeLC8m.dW70BEf.Z9b3NnHouyWeQqfq.RhZ_dS7q.hczluFBqK_czg; path=/; expires=Thu, 26-Dec-24 22:33:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=m.7dW_wzZ4v0JnPYRHxUS3.dRiMkD0rkO0bHKRAb2YQ-1735250601592-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f845c3d787ce7a4-SCL'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:03:21,488 DEBUG: request_id: req_465cd217c91839b390fd96314394b3f6 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:03:21,494 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 58, in generate_response
    new_message = response["messages"].content
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'content'
2024-12-26 19:03:21,496 INFO: 127.0.0.1 - - [26/Dec/2024 19:03:21] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:03:29,106 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:03:29,108 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:03:29,118 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:03:29,118 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:03:29,134 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:03:29,134 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:03:29,135 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,147 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1292e1350> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,147 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x129293ec0> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,172 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1292e1290> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,173 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,173 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,173 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,173 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,174 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,814 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:03:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'430'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'49.316s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_1b9ea10b5093f699e24b735154369caf'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=bBXxwu4sqC.tpa4xXsi9vfWCSrSZwZS0qTvxMCT1.SE-1735250610-1.0.1.1-aHUm.S_nKw4zlFYw0OJcDb5PKIHZy8yO9bZG6A9.a33zREJdiRzXnf5e8cxlymta.mvqcH9m3nVkmHYI_A2KUg; path=/; expires=Thu, 26-Dec-24 22:33:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=NxfmEczY5fqLN7QueEwpmNkl.LX4mQ_pAAl6JIFQV4Q-1735250610051-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f845c74ee879b23-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,815 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:03:29,815 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,817 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,817 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,817 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,817 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:03:30 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '430'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9994'), ('x-ratelimit-remaining-tokens', '199678'), ('x-ratelimit-reset-requests', '49.316s'), ('x-ratelimit-reset-tokens', '96ms'), ('x-request-id', 'req_1b9ea10b5093f699e24b735154369caf'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=bBXxwu4sqC.tpa4xXsi9vfWCSrSZwZS0qTvxMCT1.SE-1735250610-1.0.1.1-aHUm.S_nKw4zlFYw0OJcDb5PKIHZy8yO9bZG6A9.a33zREJdiRzXnf5e8cxlymta.mvqcH9m3nVkmHYI_A2KUg; path=/; expires=Thu, 26-Dec-24 22:33:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=NxfmEczY5fqLN7QueEwpmNkl.LX4mQ_pAAl6JIFQV4Q-1735250610051-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f845c74ee879b23-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:03:29,818 DEBUG: request_id: req_1b9ea10b5093f699e24b735154369caf [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:03:29,821 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:03:29,821 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:03:29,830 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:03:29,831 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:03:29,852 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:03:29,853 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:03:29,853 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,878 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1293c9550> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,879 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x1292932f0> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,909 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12929f010> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,909 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,909 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,910 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,910 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:29,911 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:31,335 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:03:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'890'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'199542'), (b'x-ratelimit-reset-requests', b'56.885s'), (b'x-ratelimit-reset-tokens', b'137ms'), (b'x-request-id', b'req_60fb3a6482df088aa3cfec1b2aa51e91'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=BBVvqJ8cvBKRpLg11dXOrVCCH5icf3CkYvthKYI3JqU-1735250611-1.0.1.1-Q4URmcFs4rcXdgNpLSc.jvg1sRZTakhxYzt_OcNQwLKeD5x0REGIOvFZyxmdyu_jXW42ruTXKWrTLezpgFjeIQ; path=/; expires=Thu, 26-Dec-24 22:33:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=bJnToNeKmqhkrEmIr7jcuTApWZl0WMjLGBwqrGBedfA-1735250611572-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f845c7998308bc0-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:31,344 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:03:31,345 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:31,353 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:31,353 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:31,353 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:03:31,354 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:03:31 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '890'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9993'), ('x-ratelimit-remaining-tokens', '199542'), ('x-ratelimit-reset-requests', '56.885s'), ('x-ratelimit-reset-tokens', '137ms'), ('x-request-id', 'req_60fb3a6482df088aa3cfec1b2aa51e91'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=BBVvqJ8cvBKRpLg11dXOrVCCH5icf3CkYvthKYI3JqU-1735250611-1.0.1.1-Q4URmcFs4rcXdgNpLSc.jvg1sRZTakhxYzt_OcNQwLKeD5x0REGIOvFZyxmdyu_jXW42ruTXKWrTLezpgFjeIQ; path=/; expires=Thu, 26-Dec-24 22:33:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=bJnToNeKmqhkrEmIr7jcuTApWZl0WMjLGBwqrGBedfA-1735250611572-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f845c7998308bc0-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:03:31,354 DEBUG: request_id: req_60fb3a6482df088aa3cfec1b2aa51e91 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:03:31,359 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 58, in generate_response
    new_message = response["messages"].content
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'content'
2024-12-26 19:03:31,360 INFO: 127.0.0.1 - - [26/Dec/2024 19:03:31] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:06:01,314 DEBUG: Closing Client.session [in /usr/local/lib/python3.11/site-packages/langsmith/client.py:332]
2024-12-26 19:06:01,323 DEBUG: Closing Client.session [in /usr/local/lib/python3.11/site-packages/langsmith/client.py:332]
2024-12-26 19:06:01,811 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:01,813 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:01,813 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:01,814 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:01,814 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:01,815 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:01,815 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:01,817 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:01,817 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:01,818 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:03,981 INFO: Flask app started [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/run.py:26]
2024-12-26 19:06:04,029 INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.186:8000 [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:06:04,029 INFO: [33mPress CTRL+C to quit[0m [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:06:13,804 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:06:13,805 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:06:13,817 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:06:13,817 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:06:18,541 INFO: Discovering subpackages in _NamespacePath(['/usr/local/lib/python3.11/site-packages/pinecone_plugins']) [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_namespace_packages.py:12]
2024-12-26 19:06:18,542 INFO: Looking for plugins in pinecone_plugins.inference [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_plugins.py:9]
2024-12-26 19:06:18,568 INFO: Installing plugin inference into Pinecone [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/installation.py:10]
2024-12-26 19:06:18,968 DEBUG: response body: b'{"name":"jumbo-ai","metric":"dotproduct","dimension":512,"status":{"ready":true,"state":"Ready"},"host":"jumbo-ai-blg7rf2.svc.aped-4627-b74a.pinecone.io","spec":{"serverless":{"region":"us-east-1","cloud":"aws"}},"deletion_protection":"disabled"}' [in /usr/local/lib/python3.11/site-packages/pinecone/core/openapi/shared/rest.py:264]
2024-12-26 19:06:19,078 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:06:19,078 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:06:19,087 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:06:19,087 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:06:22,827 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:06:22,828 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:06:22,839 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:06:22,840 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:06:22,860 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:06:22,872 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:06:22,912 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:22,991 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12d6f7050> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:22,991 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12da02e70> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:23,042 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12c9721d0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:23,042 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:23,043 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:23,043 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:23,044 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:23,044 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:23,930 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:06:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'296'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199677'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_1237f6726ced4d082d2c44727fd36b85'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=AvrmcmGyB1VpH6r1Y9QlNjClV6B.xeuzrSm0d7Ohqlc-1735250784-1.0.1.1-CgBw0vTCDsKgr2Dpgk_ECnC5H4jMGi3wKkF_SSMu0YM0xlafhFAYpD3sSpyP0uCqnsqgHQiTM8u1DJG6A9ej0w; path=/; expires=Thu, 26-Dec-24 22:36:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=BpqSxd1.DdytBirzgF.4QLwYFawEhP6kNfCIHyo_f2c-1735250784169-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f8460b3ccab9b1d-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:23,934 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:06:23,935 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:23,935 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:23,936 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:23,936 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:23,936 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:06:24 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '296'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199677'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '96ms'), ('x-request-id', 'req_1237f6726ced4d082d2c44727fd36b85'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=AvrmcmGyB1VpH6r1Y9QlNjClV6B.xeuzrSm0d7Ohqlc-1735250784-1.0.1.1-CgBw0vTCDsKgr2Dpgk_ECnC5H4jMGi3wKkF_SSMu0YM0xlafhFAYpD3sSpyP0uCqnsqgHQiTM8u1DJG6A9ej0w; path=/; expires=Thu, 26-Dec-24 22:36:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=BpqSxd1.DdytBirzgF.4QLwYFawEhP6kNfCIHyo_f2c-1735250784169-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f8460b3ccab9b1d-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:06:23,937 DEBUG: request_id: req_1237f6726ced4d082d2c44727fd36b85 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:06:23,962 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:06:23,963 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:06:23,972 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:06:23,973 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:06:23,997 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:06:23,998 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:06:23,998 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:24,036 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12d9a7310> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:24,037 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12da02b10> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:24,108 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12dafb3d0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:24,108 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:24,109 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:24,109 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:24,110 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:24,110 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:25,333 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:06:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'1020'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199541'), (b'x-ratelimit-reset-requests', b'16.595s'), (b'x-ratelimit-reset-tokens', b'137ms'), (b'x-request-id', b'req_78a2110d5bed9b87f5cbd94e9d2e6d14'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=yLaLIjdugTXjZ.CqfPSXXWR9J3QG8x6_2buIBIDc.1M-1735250785-1.0.1.1-_ZLQ_U3NzeT9BwHSAi80cLhD2rNxIGfdYlruidaBubk.dbiFp375DHayasFKDpqhzXg4eQ2WAdxEuWmR8e9CQg; path=/; expires=Thu, 26-Dec-24 22:36:25 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=TIPF9CvMl6kNb0detXfivk1IFPCVO93PJntTi_pAI50-1735250785567-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f8460ba7fe6e79b-SCL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:25,335 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:06:25,336 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:25,337 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:25,337 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:25,337 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:06:25,338 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:06:25 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '1020'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9998'), ('x-ratelimit-remaining-tokens', '199541'), ('x-ratelimit-reset-requests', '16.595s'), ('x-ratelimit-reset-tokens', '137ms'), ('x-request-id', 'req_78a2110d5bed9b87f5cbd94e9d2e6d14'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=yLaLIjdugTXjZ.CqfPSXXWR9J3QG8x6_2buIBIDc.1M-1735250785-1.0.1.1-_ZLQ_U3NzeT9BwHSAi80cLhD2rNxIGfdYlruidaBubk.dbiFp375DHayasFKDpqhzXg4eQ2WAdxEuWmR8e9CQg; path=/; expires=Thu, 26-Dec-24 22:36:25 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=TIPF9CvMl6kNb0detXfivk1IFPCVO93PJntTi_pAI50-1735250785567-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f8460ba7fe6e79b-SCL'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:06:25,338 DEBUG: request_id: req_78a2110d5bed9b87f5cbd94e9d2e6d14 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:06:26,442 ERROR: Request failed due to: 401 Client Error: Unauthorized for url: https://graph.facebook.com/v21.0/500884943114067/messages [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:51]
2024-12-26 19:06:26,443 INFO: 127.0.0.1 - - [26/Dec/2024 19:06:26] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:08:07,715 DEBUG: Closing Client.session [in /usr/local/lib/python3.11/site-packages/langsmith/client.py:332]
2024-12-26 19:08:07,722 DEBUG: Closing Client.session [in /usr/local/lib/python3.11/site-packages/langsmith/client.py:332]
2024-12-26 19:08:08,142 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:08,142 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:08,143 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:08,144 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:10,265 INFO: Flask app started [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/run.py:26]
2024-12-26 19:08:10,302 INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.186:8000 [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:08:10,302 INFO: [33mPress CTRL+C to quit[0m [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:08:27,737 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:08:27,738 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:08:27,750 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:08:27,750 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:08:33,379 INFO: Discovering subpackages in _NamespacePath(['/usr/local/lib/python3.11/site-packages/pinecone_plugins']) [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_namespace_packages.py:12]
2024-12-26 19:08:33,380 INFO: Looking for plugins in pinecone_plugins.inference [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_plugins.py:9]
2024-12-26 19:08:33,401 INFO: Installing plugin inference into Pinecone [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/installation.py:10]
2024-12-26 19:08:34,091 DEBUG: response body: b'{"name":"jumbo-ai","metric":"dotproduct","dimension":512,"status":{"ready":true,"state":"Ready"},"host":"jumbo-ai-blg7rf2.svc.aped-4627-b74a.pinecone.io","spec":{"serverless":{"region":"us-east-1","cloud":"aws"}},"deletion_protection":"disabled"}' [in /usr/local/lib/python3.11/site-packages/pinecone/core/openapi/shared/rest.py:264]
2024-12-26 19:08:34,206 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:08:34,206 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:08:34,214 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:08:34,215 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:08:39,720 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:08:39,721 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:08:39,731 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:08:39,732 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:08:39,753 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:08:39,755 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:08:39,755 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:39,840 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12dc1f850> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:39,841 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12df9ef00> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:39,879 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12dff8e10> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:39,879 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:39,880 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:39,880 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:39,880 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:39,881 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:39,918 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:08:39,919 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:08:39,932 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:08:39,932 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:08:39,948 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:08:39,949 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:08:39,949 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:39,970 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e061e90> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:39,971 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12df9f1d0> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,025 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e01bad0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,026 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,028 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,029 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,029 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,030 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,677 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:08:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'195'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199590'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'123ms'), (b'x-request-id', b'req_a1c03be13e4f8b74725307016a8fa9f7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Grw6fdggMOhKdiF2QQRUTJsY12wfND4edk49F_R0ybc-1735250920-1.0.1.1-7uWDlofQ0jTjWhBj5ikCbw79jUiUHYewZB7fVz866rW87VaincwiKt0EtSGi0wYKpkS2Gt6reHcJuftw2emp_Q; path=/; expires=Thu, 26-Dec-24 22:38:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=kLqJW9gX3Gxgea7RuOZjbWdBaoRJ.S7MpKgdr8c3hCw-1735250920922-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f84640b2b599c0b-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,680 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:08:40,681 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,682 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,682 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,682 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,683 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:08:40 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '195'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199590'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '123ms'), ('x-request-id', 'req_a1c03be13e4f8b74725307016a8fa9f7'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Grw6fdggMOhKdiF2QQRUTJsY12wfND4edk49F_R0ybc-1735250920-1.0.1.1-7uWDlofQ0jTjWhBj5ikCbw79jUiUHYewZB7fVz866rW87VaincwiKt0EtSGi0wYKpkS2Gt6reHcJuftw2emp_Q; path=/; expires=Thu, 26-Dec-24 22:38:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=kLqJW9gX3Gxgea7RuOZjbWdBaoRJ.S7MpKgdr8c3hCw-1735250920922-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f84640b2b599c0b-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:08:40,683 DEBUG: request_id: req_a1c03be13e4f8b74725307016a8fa9f7 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:08:40,712 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:08:40,713 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:08:40,724 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:08:40,724 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:08:40,749 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:08:40,750 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:08:40,750 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,771 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:08:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'178'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199568'), (b'x-ratelimit-reset-requests', b'17.163s'), (b'x-ratelimit-reset-tokens', b'129ms'), (b'x-request-id', b'req_b1db184673b61f24d862336a01cf8a5f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=pZfK32KEXYLxCnNYq35u_N5SiixPj4ZfsuQ0F1NJTtM-1735250921-1.0.1.1-Ng0xOGVXWplwG7bpf2eUlq2XZ_2II32VURflbiipN8xFh7RXImtijlU0mECg_XRHn9OmY6vm55IwbyQM7keE9w; path=/; expires=Thu, 26-Dec-24 22:38:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=j8XgrLZjUbfGqHO25l._wyi2.RXFtOl8pmj7762kjPE-1735250921016-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f84640c0e5f9c11-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,773 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:08:40,774 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,775 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,775 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,775 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,776 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:08:41 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '178'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9998'), ('x-ratelimit-remaining-tokens', '199568'), ('x-ratelimit-reset-requests', '17.163s'), ('x-ratelimit-reset-tokens', '129ms'), ('x-request-id', 'req_b1db184673b61f24d862336a01cf8a5f'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=pZfK32KEXYLxCnNYq35u_N5SiixPj4ZfsuQ0F1NJTtM-1735250921-1.0.1.1-Ng0xOGVXWplwG7bpf2eUlq2XZ_2II32VURflbiipN8xFh7RXImtijlU0mECg_XRHn9OmY6vm55IwbyQM7keE9w; path=/; expires=Thu, 26-Dec-24 22:38:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=j8XgrLZjUbfGqHO25l._wyi2.RXFtOl8pmj7762kjPE-1735250921016-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f84640c0e5f9c11-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:08:40,776 DEBUG: request_id: req_b1db184673b61f24d862336a01cf8a5f [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:08:40,783 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:08:40,784 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:08:40,796 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,796 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e89ab90> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,796 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,796 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12df9fc80> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,800 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:08:40,801 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:08:40,828 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:08:40,828 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:08:40,829 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,988 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e004210> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,989 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,989 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,990 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,990 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:40,990 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:41,058 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e8c37d0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:41,108 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12df9ea80> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:41,248 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e8b21d0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:41,248 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:41,248 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:41,248 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:41,249 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:41,249 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:41,997 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:08:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'587'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199448'), (b'x-ratelimit-reset-requests', b'24.998s'), (b'x-ratelimit-reset-tokens', b'165ms'), (b'x-request-id', b'req_63ffeb8e09ed9127fe01c91d0a91596b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=RY89_ZtY42o_ZrpXkU8U6sWdGic5GScmimn3JPrWJC0-1735250922-1.0.1.1-e47lTWHJ6W_s3dfmm.75pniWdyMAjcBSYt9fO_dgKQ2UHkM1CBwyicISbpkos9FY9WMdhcDXPHzLy3zCqEtsuQ; path=/; expires=Thu, 26-Dec-24 22:38:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=QTJIoBQkWuXNCEJ7Xvbg6rEnrwQ6gpTUxgz083Cbemg-1735250922219-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f846412cfa2a782-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:41,999 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:08:41,999 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:42,000 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:42,000 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:42,001 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:42,001 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:08:42 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '587'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9997'), ('x-ratelimit-remaining-tokens', '199448'), ('x-ratelimit-reset-requests', '24.998s'), ('x-ratelimit-reset-tokens', '165ms'), ('x-request-id', 'req_63ffeb8e09ed9127fe01c91d0a91596b'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=RY89_ZtY42o_ZrpXkU8U6sWdGic5GScmimn3JPrWJC0-1735250922-1.0.1.1-e47lTWHJ6W_s3dfmm.75pniWdyMAjcBSYt9fO_dgKQ2UHkM1CBwyicISbpkos9FY9WMdhcDXPHzLy3zCqEtsuQ; path=/; expires=Thu, 26-Dec-24 22:38:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=QTJIoBQkWuXNCEJ7Xvbg6rEnrwQ6gpTUxgz083Cbemg-1735250922219-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f846412cfa2a782-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:08:42,002 DEBUG: request_id: req_63ffeb8e09ed9127fe01c91d0a91596b [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:08:42,156 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:08:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'687'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'199156'), (b'x-ratelimit-reset-requests', b'33.56s'), (b'x-ratelimit-reset-tokens', b'253ms'), (b'x-request-id', b'req_24ba4d5757444a71ff2dfb63ef768735'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=w66kXTx5BuFMF2v6MbDj8IRYhfHuzUowRaJIz8_5IDw-1735250922-1.0.1.1-E_H6.i_VvztzB5AqhaSggOsHO5u6JWLRt3oeoE_HTZ7viLL.NA71B8Hd9Qc5s9nELwuJa2gI7MvxsNwRohhWtA; path=/; expires=Thu, 26-Dec-24 22:38:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=_g6J1WAqaC_46sum6dHsqRzGTu05aXbDTo5.9GPPhSo-1735250922382-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f846413abe2e9b6-SCL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:42,158 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:08:42,158 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:42,164 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:42,164 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:42,164 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:08:42,165 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:08:42 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '687'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9996'), ('x-ratelimit-remaining-tokens', '199156'), ('x-ratelimit-reset-requests', '33.56s'), ('x-ratelimit-reset-tokens', '253ms'), ('x-request-id', 'req_24ba4d5757444a71ff2dfb63ef768735'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=w66kXTx5BuFMF2v6MbDj8IRYhfHuzUowRaJIz8_5IDw-1735250922-1.0.1.1-E_H6.i_VvztzB5AqhaSggOsHO5u6JWLRt3oeoE_HTZ7viLL.NA71B8Hd9Qc5s9nELwuJa2gI7MvxsNwRohhWtA; path=/; expires=Thu, 26-Dec-24 22:38:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=_g6J1WAqaC_46sum6dHsqRzGTu05aXbDTo5.9GPPhSo-1735250922382-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f846413abe2e9b6-SCL'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:08:42,165 DEBUG: request_id: req_24ba4d5757444a71ff2dfb63ef768735 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:08:46,071 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 19:08:46,071 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 19:08:46,071 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkI4OTIzRTU1NjA5N0EzNzZEMwA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 19:08:46,072 INFO: 127.0.0.1 - - [26/Dec/2024 19:08:46] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:08:46,074 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 19:08:46,074 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 19:08:46,074 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkMxOUY0QjQyQTBFNEFFNENBMQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 19:08:46,074 INFO: 127.0.0.1 - - [26/Dec/2024 19:08:46] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:08:46,985 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:08:46,986 INFO: 127.0.0.1 - - [26/Dec/2024 19:08:46] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:08:47,053 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:08:47,054 INFO: 127.0.0.1 - - [26/Dec/2024 19:08:47] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:08:47,560 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:08:47,561 INFO: 127.0.0.1 - - [26/Dec/2024 19:08:47] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:08:47,641 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:08:47,643 INFO: 127.0.0.1 - - [26/Dec/2024 19:08:47] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:08:47,650 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:08:47,670 INFO: 127.0.0.1 - - [26/Dec/2024 19:08:47] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:08:47,768 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:08:47,768 INFO: 127.0.0.1 - - [26/Dec/2024 19:08:47] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:09:16,733 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:16,738 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:16,804 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:16,805 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:16,824 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:09:16,826 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:09:16,826 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:16,860 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12dfcbf10> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:16,860 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12df9ed50> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:16,970 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12dfca450> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:16,971 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:16,972 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:16,972 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:16,972 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:16,973 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:17,541 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:09:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'214'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199542'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'137ms'), (b'x-request-id', b'req_f752fe62e9b67f674354466db201c1eb'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=85g3FP8anGvlLpLeZOKIvl3aSYTH7s5PvMnEeOjAQ04-1735250957-1.0.1.1-gKOi4Lv3WjcqQc1B4v3IG0.Fusl3Vsjk2YmfyB4UKSJrvLmqO8HiZtw6lzujYoz6p8UbMlqp2A7SvrEr438Fiw; path=/; expires=Thu, 26-Dec-24 22:39:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=5OG8SQdD9zxKDDW9PExeyJjGfup8d0HnYdczMrznDrA-1735250957770-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f8464f35f251e82-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:17,545 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:09:17,553 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:17,554 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:17,554 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:17,554 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:17,555 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:09:17 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '214'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199542'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '137ms'), ('x-request-id', 'req_f752fe62e9b67f674354466db201c1eb'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=85g3FP8anGvlLpLeZOKIvl3aSYTH7s5PvMnEeOjAQ04-1735250957-1.0.1.1-gKOi4Lv3WjcqQc1B4v3IG0.Fusl3Vsjk2YmfyB4UKSJrvLmqO8HiZtw6lzujYoz6p8UbMlqp2A7SvrEr438Fiw; path=/; expires=Thu, 26-Dec-24 22:39:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=5OG8SQdD9zxKDDW9PExeyJjGfup8d0HnYdczMrznDrA-1735250957770-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f8464f35f251e82-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:09:17,555 DEBUG: request_id: req_f752fe62e9b67f674354466db201c1eb [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:09:17,563 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:17,564 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:17,575 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:17,575 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:17,621 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:09:17,622 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:09:17,623 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:17,642 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12dfcb8d0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:17,642 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12df9f2f0> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:17,708 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12df44710> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:17,708 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:17,709 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:17,709 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:17,709 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:17,709 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:18,463 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:09:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'501'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199305'), (b'x-ratelimit-reset-requests', b'16.64s'), (b'x-ratelimit-reset-tokens', b'208ms'), (b'x-request-id', b'req_0c4b5b3658003363ba3fb14e6d562c7c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=fVV8DsoXHhclI3x4ZEZS4Npp4I3cLIWc0.eJTPggrkQ-1735250958-1.0.1.1-jrD_4Rv.Qi4mlUKWZEcws.sHfp55D5OMvDLr9OVLGVYOUrjTlXL3dXWuUqsSTGurWID3xS.xSMNWjcl5rUrebQ; path=/; expires=Thu, 26-Dec-24 22:39:18 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=MxWzkK61qTa0K0sMEejqlMMO5nEL6b7f15ii29FD4ys-1735250958699-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f8464f779569b1a-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:18,464 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:09:18,464 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:18,465 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:18,465 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:18,465 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:18,465 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:09:18 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '501'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9998'), ('x-ratelimit-remaining-tokens', '199305'), ('x-ratelimit-reset-requests', '16.64s'), ('x-ratelimit-reset-tokens', '208ms'), ('x-request-id', 'req_0c4b5b3658003363ba3fb14e6d562c7c'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=fVV8DsoXHhclI3x4ZEZS4Npp4I3cLIWc0.eJTPggrkQ-1735250958-1.0.1.1-jrD_4Rv.Qi4mlUKWZEcws.sHfp55D5OMvDLr9OVLGVYOUrjTlXL3dXWuUqsSTGurWID3xS.xSMNWjcl5rUrebQ; path=/; expires=Thu, 26-Dec-24 22:39:18 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=MxWzkK61qTa0K0sMEejqlMMO5nEL6b7f15ii29FD4ys-1735250958699-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f8464f779569b1a-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:09:18,476 DEBUG: request_id: req_0c4b5b3658003363ba3fb14e6d562c7c [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:09:18,695 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 57, in generate_response
    response = invoke_our_graph(state)
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 24, in invoke_our_graph
    response = graph_runnable.invoke(state)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1535, in invoke
    for chunk in self.stream(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1273, in stream
    for _ in runner.tick(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/runner.py", line 56, in tick
    run_with_retry(t, retry_policy)
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/retry.py", line 29, in run_with_retry
    task.proc.invoke(task.input, config)
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 410, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 141, in invoke
    raise TypeError(
TypeError: No synchronous function provided to "save_memory".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2024-12-26 19:09:18,700 INFO: 127.0.0.1 - - [26/Dec/2024 19:09:18] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:09:20,845 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:20,846 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:20,859 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:20,859 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:20,871 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:20,872 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:20,872 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:20,872 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:20,885 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:09:20,885 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:09:20,886 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,029 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e063510> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,030 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12e8d4cb0> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,150 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e912950> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,151 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,151 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,151 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,152 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,152 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,567 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:09:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'218'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199603'), (b'x-ratelimit-reset-requests', b'21.855s'), (b'x-ratelimit-reset-tokens', b'119ms'), (b'x-request-id', b'req_f8b13f080032497d470e4bbed86b2d8e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=tZXlHU1MMs0qjrGWzH1EDwAochVulduiizvgNfpG5QI-1735250961-1.0.1.1-hJAJk7pI05viUAq4uIgvvRq_7EZarFqtfuTg0B0ka27Fgy5mcVnbhak3mlpT6qLIZAzTx9KOqkSkgHCZTYtt7Q; path=/; expires=Thu, 26-Dec-24 22:39:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=q60xM7UBnOSwQo2EMWck4XpoGrAUr4YLwuHPuX.euF8-1735250961812-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f84650cff17e9a3-SCL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,569 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:09:21,569 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,570 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,570 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,570 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,571 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:09:21 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '218'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9997'), ('x-ratelimit-remaining-tokens', '199603'), ('x-ratelimit-reset-requests', '21.855s'), ('x-ratelimit-reset-tokens', '119ms'), ('x-request-id', 'req_f8b13f080032497d470e4bbed86b2d8e'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=tZXlHU1MMs0qjrGWzH1EDwAochVulduiizvgNfpG5QI-1735250961-1.0.1.1-hJAJk7pI05viUAq4uIgvvRq_7EZarFqtfuTg0B0ka27Fgy5mcVnbhak3mlpT6qLIZAzTx9KOqkSkgHCZTYtt7Q; path=/; expires=Thu, 26-Dec-24 22:39:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=q60xM7UBnOSwQo2EMWck4XpoGrAUr4YLwuHPuX.euF8-1735250961812-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f84650cff17e9a3-SCL'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:09:21,572 DEBUG: request_id: req_f8b13f080032497d470e4bbed86b2d8e [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:09:21,579 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:21,579 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:21,593 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:21,593 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:21,627 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:09:21,628 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:09:21,628 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,667 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e8a5890> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,667 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12e8d4f80> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,735 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e8a53d0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,735 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,736 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,736 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,736 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:21,736 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:22,949 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:09:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'522'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'199301'), (b'x-ratelimit-reset-requests', b'29.612s'), (b'x-ratelimit-reset-tokens', b'209ms'), (b'x-request-id', b'req_b1ee46c671ec339dde9c95ea9f06ca70'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=U36bt8LBnKikeznhBp0505wXLKKwHxo6NrlEOBDlpJE-1735250963-1.0.1.1-ZJDFZZaLIedvSImj93P2RfniXYCS9rHoNH8s4yBG5Bj2RuIQmOiOswi2EMJIHJJiP1dM4PJ7DgRXG5l03AFa4Q; path=/; expires=Thu, 26-Dec-24 22:39:23 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=6sYOtODzskoMnGqNpYpqvyT6r11uu4.l3HEchxBm52w-1735250963083-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f84651099a59c0f-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:22,950 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:09:22,951 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:22,951 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:22,951 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:22,951 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:22,952 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:09:23 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '522'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9996'), ('x-ratelimit-remaining-tokens', '199301'), ('x-ratelimit-reset-requests', '29.612s'), ('x-ratelimit-reset-tokens', '209ms'), ('x-request-id', 'req_b1ee46c671ec339dde9c95ea9f06ca70'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=U36bt8LBnKikeznhBp0505wXLKKwHxo6NrlEOBDlpJE-1735250963-1.0.1.1-ZJDFZZaLIedvSImj93P2RfniXYCS9rHoNH8s4yBG5Bj2RuIQmOiOswi2EMJIHJJiP1dM4PJ7DgRXG5l03AFa4Q; path=/; expires=Thu, 26-Dec-24 22:39:23 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=6sYOtODzskoMnGqNpYpqvyT6r11uu4.l3HEchxBm52w-1735250963083-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f84651099a59c0f-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:09:22,952 DEBUG: request_id: req_b1ee46c671ec339dde9c95ea9f06ca70 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:09:22,959 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 57, in generate_response
    response = invoke_our_graph(state)
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 24, in invoke_our_graph
    response = graph_runnable.invoke(state)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1535, in invoke
    for chunk in self.stream(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1273, in stream
    for _ in runner.tick(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/runner.py", line 56, in tick
    run_with_retry(t, retry_policy)
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/retry.py", line 29, in run_with_retry
    task.proc.invoke(task.input, config)
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 410, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 141, in invoke
    raise TypeError(
TypeError: No synchronous function provided to "save_memory".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2024-12-26 19:09:22,960 INFO: 127.0.0.1 - - [26/Dec/2024 19:09:22] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:09:25,919 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:25,919 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:25,931 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:25,932 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:25,947 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:09:25,948 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:09:25,948 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:25,973 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12df00e90> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:25,973 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12df9e960> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,017 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e0cb6d0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,018 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,018 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,018 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,019 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,019 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,443 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:09:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'190'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'199672'), (b'x-ratelimit-reset-requests', b'34.234s'), (b'x-ratelimit-reset-tokens', b'98ms'), (b'x-request-id', b'req_192b50bc3b5afd917262444535b1a344'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YkoBIFibiBk7M0xlTC75ls7WUmaM4KcnZTE3aBXePPo-1735250966-1.0.1.1-BnGu4EVb7xszdp0j0UXVsb49lejqJeTuLi7Y4MHXwidxJSvLXVOWMN8NwWh0uGj7wvJzoe1pwEiC8rtOAcP6MA; path=/; expires=Thu, 26-Dec-24 22:39:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=G5f3q2AJFPUv.B3G2OsDoTzEtUO9LXE0JP67Ia4s7rs-1735250966698-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f84652b7f3f202c-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,444 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:09:26,445 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,445 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,446 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,446 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,446 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:09:26 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '190'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9996'), ('x-ratelimit-remaining-tokens', '199672'), ('x-ratelimit-reset-requests', '34.234s'), ('x-ratelimit-reset-tokens', '98ms'), ('x-request-id', 'req_192b50bc3b5afd917262444535b1a344'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=YkoBIFibiBk7M0xlTC75ls7WUmaM4KcnZTE3aBXePPo-1735250966-1.0.1.1-BnGu4EVb7xszdp0j0UXVsb49lejqJeTuLi7Y4MHXwidxJSvLXVOWMN8NwWh0uGj7wvJzoe1pwEiC8rtOAcP6MA; path=/; expires=Thu, 26-Dec-24 22:39:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=G5f3q2AJFPUv.B3G2OsDoTzEtUO9LXE0JP67Ia4s7rs-1735250966698-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f84652b7f3f202c-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:09:26,447 DEBUG: request_id: req_192b50bc3b5afd917262444535b1a344 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:09:26,455 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:26,456 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:26,468 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:26,468 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:26,499 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:09:26,500 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:09:26,500 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,658 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e9315d0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,658 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12e8f49e0> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,684 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e956bd0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,685 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,685 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,685 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,686 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:26,686 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:27,430 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:09:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'445'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9995'), (b'x-ratelimit-remaining-tokens', b'199297'), (b'x-ratelimit-reset-requests', b'42.187s'), (b'x-ratelimit-reset-tokens', b'210ms'), (b'x-request-id', b'req_ab2bff15dac9c1403f2a105b0eadfad3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.dB2XLQoEbJFK.4.v0iYh70cdS1_IyUW4yBRXIb.7O8-1735250967-1.0.1.1-JVyCvwGj9ka.kSCQ5V6hFkHra4KjHzRNevS2bgVxoVgrFLRzPl0J2pd7etxJLzfgTk_NnId1hyIM8x6MrqHWrg; path=/; expires=Thu, 26-Dec-24 22:39:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=D0JaJFiZrtgxq.J8yaI4ngGQDtHdVkKIgM_L2b0CHRg-1735250967633-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f84652fce089c0f-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:27,432 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:09:27,432 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:27,432 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:27,433 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:27,433 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:27,433 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:09:27 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '445'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9995'), ('x-ratelimit-remaining-tokens', '199297'), ('x-ratelimit-reset-requests', '42.187s'), ('x-ratelimit-reset-tokens', '210ms'), ('x-request-id', 'req_ab2bff15dac9c1403f2a105b0eadfad3'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=.dB2XLQoEbJFK.4.v0iYh70cdS1_IyUW4yBRXIb.7O8-1735250967-1.0.1.1-JVyCvwGj9ka.kSCQ5V6hFkHra4KjHzRNevS2bgVxoVgrFLRzPl0J2pd7etxJLzfgTk_NnId1hyIM8x6MrqHWrg; path=/; expires=Thu, 26-Dec-24 22:39:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=D0JaJFiZrtgxq.J8yaI4ngGQDtHdVkKIgM_L2b0CHRg-1735250967633-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f84652fce089c0f-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:09:27,434 DEBUG: request_id: req_ab2bff15dac9c1403f2a105b0eadfad3 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:09:27,443 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 57, in generate_response
    response = invoke_our_graph(state)
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 24, in invoke_our_graph
    response = graph_runnable.invoke(state)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1535, in invoke
    for chunk in self.stream(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1273, in stream
    for _ in runner.tick(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/runner.py", line 56, in tick
    run_with_retry(t, retry_policy)
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/retry.py", line 29, in run_with_retry
    task.proc.invoke(task.input, config)
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 410, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 141, in invoke
    raise TypeError(
TypeError: No synchronous function provided to "save_memory".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2024-12-26 19:09:27,445 INFO: 127.0.0.1 - - [26/Dec/2024 19:09:27] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:09:31,690 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:31,690 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:31,702 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:31,703 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:31,718 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:09:31,718 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:09:31,719 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:31,760 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e974b50> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:31,761 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12df9fb60> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:31,825 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12dbfd910> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:31,826 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:31,826 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:31,826 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:31,826 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:31,826 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:32,367 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:09:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'179'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'199672'), (b'x-ratelimit-reset-requests', b'45.655s'), (b'x-ratelimit-reset-tokens', b'98ms'), (b'x-request-id', b'req_e66799c710ed0f357590b33c2a5047d4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=HvZ7wS6zpam2AF8sr57fvOxPAB.6S6XdVG5bvCLmWoU-1735250972-1.0.1.1-Ug42npxQZ3PIwXefexoVsXcl8I5VjYJbgHJDOQ9RlUDCeZcNrO3wg3znocJ3bjnSlytM9hLCDGUs0l6Q6tfHpg; path=/; expires=Thu, 26-Dec-24 22:39:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=kmIS5FxIrHlS2VNF3we2yMrK8Hmvaao_692Ao1n4pJY-1735250972543-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f84654fefb61e80-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:32,369 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:09:32,369 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:32,393 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:32,394 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:32,394 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:32,394 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:09:32 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '179'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9994'), ('x-ratelimit-remaining-tokens', '199672'), ('x-ratelimit-reset-requests', '45.655s'), ('x-ratelimit-reset-tokens', '98ms'), ('x-request-id', 'req_e66799c710ed0f357590b33c2a5047d4'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=HvZ7wS6zpam2AF8sr57fvOxPAB.6S6XdVG5bvCLmWoU-1735250972-1.0.1.1-Ug42npxQZ3PIwXefexoVsXcl8I5VjYJbgHJDOQ9RlUDCeZcNrO3wg3znocJ3bjnSlytM9hLCDGUs0l6Q6tfHpg; path=/; expires=Thu, 26-Dec-24 22:39:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=kmIS5FxIrHlS2VNF3we2yMrK8Hmvaao_692Ao1n4pJY-1735250972543-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f84654fefb61e80-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:09:32,395 DEBUG: request_id: req_e66799c710ed0f357590b33c2a5047d4 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:09:32,403 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:32,403 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:32,417 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:32,417 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:32,430 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:32,430 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:32,431 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:32,431 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:32,431 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:32,431 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:32,431 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:32,431 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:32,458 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:09:32,459 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:09:32,459 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:32,949 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12cbf4bd0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:32,950 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12e8f4f80> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:33,308 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12dc1de50> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:33,308 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:33,308 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:33,308 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:33,309 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:33,309 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:35,186 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:09:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'688'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'199293'), (b'x-ratelimit-reset-requests', b'51.943s'), (b'x-ratelimit-reset-tokens', b'211ms'), (b'x-request-id', b'req_ee2ba61e71d29479e06d661920109d90'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=q2uELjp2Y8o6qJ8rAH38D3wuHEh7HQRcWFZVJaxmj3w-1735250975-1.0.1.1-e4DVTqWzx7QRDB_KASIs4jrWtX7rJl6vnAXzFlz1pcvA9JpZdykm31fnWKPes_diXjISZttjsDhmJC16Bx0lyA; path=/; expires=Thu, 26-Dec-24 22:39:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=dg7tqiI29yzalXPNL24T6Sk9GIiFnmwJz9Tgz01A_Ag-1735250975391-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f84655eef48e9a8-SCL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:35,189 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:09:35,189 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:35,237 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:35,237 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:35,237 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:35,238 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:09:35 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '688'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9993'), ('x-ratelimit-remaining-tokens', '199293'), ('x-ratelimit-reset-requests', '51.943s'), ('x-ratelimit-reset-tokens', '211ms'), ('x-request-id', 'req_ee2ba61e71d29479e06d661920109d90'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=q2uELjp2Y8o6qJ8rAH38D3wuHEh7HQRcWFZVJaxmj3w-1735250975-1.0.1.1-e4DVTqWzx7QRDB_KASIs4jrWtX7rJl6vnAXzFlz1pcvA9JpZdykm31fnWKPes_diXjISZttjsDhmJC16Bx0lyA; path=/; expires=Thu, 26-Dec-24 22:39:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=dg7tqiI29yzalXPNL24T6Sk9GIiFnmwJz9Tgz01A_Ag-1735250975391-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f84655eef48e9a8-SCL'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:09:35,238 DEBUG: request_id: req_ee2ba61e71d29479e06d661920109d90 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:09:35,247 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 57, in generate_response
    response = invoke_our_graph(state)
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 24, in invoke_our_graph
    response = graph_runnable.invoke(state)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1535, in invoke
    for chunk in self.stream(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1273, in stream
    for _ in runner.tick(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/runner.py", line 56, in tick
    run_with_retry(t, retry_policy)
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/retry.py", line 29, in run_with_retry
    task.proc.invoke(task.input, config)
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 410, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 141, in invoke
    raise TypeError(
TypeError: No synchronous function provided to "save_memory".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2024-12-26 19:09:35,249 INFO: 127.0.0.1 - - [26/Dec/2024 19:09:35] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:09:59,286 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:59,287 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:59,304 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:09:59,304 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:09:59,320 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:09:59,321 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:09:59,321 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:59,401 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e936410> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:59,401 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12df9f530> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:59,527 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e934390> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:59,527 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:59,528 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:59,528 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:59,528 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:09:59,528 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:00,276 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:10:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'391'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9995'), (b'x-ratelimit-remaining-tokens', b'199676'), (b'x-ratelimit-reset-requests', b'35.22s'), (b'x-ratelimit-reset-tokens', b'97ms'), (b'x-request-id', b'req_c7d11768d5c06b6f3e0b6a1321c34f6f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=FktCJeQtaG2AM7jTF88KzefqrN.cgYM083Gxn.n3FoI-1735251000-1.0.1.1-5oQfxZDHw9CGaIQQoV.kCVINOKDjCqJncA19H3TjTURo0KjtOkGveyiMWxg0L5_yJbrFgq3fI2qCQZ62Q9ppog; path=/; expires=Thu, 26-Dec-24 22:40:00 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=JZv8BMv9phgKs5Y5nxEdKeZwpxMp1VBqNE.Oy5A.7vE-1735251000469-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f8465fd0dc6a79c-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:00,277 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:10:00,277 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:00,278 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:00,278 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:00,278 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:00,278 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:10:00 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '391'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9995'), ('x-ratelimit-remaining-tokens', '199676'), ('x-ratelimit-reset-requests', '35.22s'), ('x-ratelimit-reset-tokens', '97ms'), ('x-request-id', 'req_c7d11768d5c06b6f3e0b6a1321c34f6f'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=FktCJeQtaG2AM7jTF88KzefqrN.cgYM083Gxn.n3FoI-1735251000-1.0.1.1-5oQfxZDHw9CGaIQQoV.kCVINOKDjCqJncA19H3TjTURo0KjtOkGveyiMWxg0L5_yJbrFgq3fI2qCQZ62Q9ppog; path=/; expires=Thu, 26-Dec-24 22:40:00 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=JZv8BMv9phgKs5Y5nxEdKeZwpxMp1VBqNE.Oy5A.7vE-1735251000469-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f8465fd0dc6a79c-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:10:00,279 DEBUG: request_id: req_c7d11768d5c06b6f3e0b6a1321c34f6f [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:10:00,286 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:10:00,286 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:10:00,299 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:10:00,299 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:10:00,331 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:10:00,332 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:10:00,332 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:00,371 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e90a990> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:00,371 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12e8f7bf0> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:00,462 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e098110> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:00,462 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:00,463 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:00,463 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:00,463 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:00,463 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:01,602 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:10:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'894'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9995'), (b'x-ratelimit-remaining-tokens', b'199293'), (b'x-ratelimit-reset-requests', b'43s'), (b'x-ratelimit-reset-tokens', b'211ms'), (b'x-request-id', b'req_1c9eac4543e483886e51548bbcd180a1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=1sDnYZptZXaPy1f8oksoNjgeoUr9PT7Rz1boy73Dl.A-1735251001-1.0.1.1-LQBqB0FZ11Lj6k8mQaRvA3Di3NqhEItjpZq8bih2wkrOh4aPMtdSou9ey7RouGTPHr5LnC6XhfltAzKRTSOCog; path=/; expires=Thu, 26-Dec-24 22:40:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=4I2Uc4PUjV6wz2Tpb3w6LXYLpxcZcE8cDVgYADF.TXs-1735251001860-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f846602af1b9b1a-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:01,604 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:10:01,604 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:01,605 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:01,605 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:01,605 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:01,605 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:10:01 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '894'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9995'), ('x-ratelimit-remaining-tokens', '199293'), ('x-ratelimit-reset-requests', '43s'), ('x-ratelimit-reset-tokens', '211ms'), ('x-request-id', 'req_1c9eac4543e483886e51548bbcd180a1'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=1sDnYZptZXaPy1f8oksoNjgeoUr9PT7Rz1boy73Dl.A-1735251001-1.0.1.1-LQBqB0FZ11Lj6k8mQaRvA3Di3NqhEItjpZq8bih2wkrOh4aPMtdSou9ey7RouGTPHr5LnC6XhfltAzKRTSOCog; path=/; expires=Thu, 26-Dec-24 22:40:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=4I2Uc4PUjV6wz2Tpb3w6LXYLpxcZcE8cDVgYADF.TXs-1735251001860-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f846602af1b9b1a-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:10:01,606 DEBUG: request_id: req_1c9eac4543e483886e51548bbcd180a1 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:10:01,616 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 57, in generate_response
    response = invoke_our_graph(state)
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 24, in invoke_our_graph
    response = graph_runnable.invoke(state)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1535, in invoke
    for chunk in self.stream(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1273, in stream
    for _ in runner.tick(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/runner.py", line 56, in tick
    run_with_retry(t, retry_policy)
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/retry.py", line 29, in run_with_retry
    task.proc.invoke(task.input, config)
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 410, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 141, in invoke
    raise TypeError(
TypeError: No synchronous function provided to "save_memory".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2024-12-26 19:10:01,618 INFO: 127.0.0.1 - - [26/Dec/2024 19:10:01] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:10:03,988 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:10:03,989 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:10:04,001 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:10:04,001 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:10:04,016 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:10:04,017 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:10:04,017 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:04,060 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e9abfd0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:04,061 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12e8f7a40> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:04,348 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e9abed0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:04,348 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:04,349 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:04,349 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:04,349 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:04,350 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:04,942 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:10:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'229'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'199673'), (b'x-ratelimit-reset-requests', b'47.658s'), (b'x-ratelimit-reset-tokens', b'97ms'), (b'x-request-id', b'req_e632fa9c2a7cd5a02ee62ddc18f0050a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=G_.u5kyelbAg6bRx5_cXu1pGMVwru8FecTGRNkYx9yA-1735251005-1.0.1.1-tLO9T73dchuDJRerRK1KiGX18aL16XAFXhGp8dRxcUC9DwXClDRXR.klqRnf2IB6Q1sYeSepPPnDsYDR5UejpA; path=/; expires=Thu, 26-Dec-24 22:40:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=l3nM_E6FJb0_cEFNaK2A3mH4Lnh.Mi1rO3YpAJngtGw-1735251005172-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f84661b6de42014-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:04,943 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:10:04,944 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:04,945 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:04,945 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:04,945 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:04,946 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:10:05 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '229'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9994'), ('x-ratelimit-remaining-tokens', '199673'), ('x-ratelimit-reset-requests', '47.658s'), ('x-ratelimit-reset-tokens', '97ms'), ('x-request-id', 'req_e632fa9c2a7cd5a02ee62ddc18f0050a'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=G_.u5kyelbAg6bRx5_cXu1pGMVwru8FecTGRNkYx9yA-1735251005-1.0.1.1-tLO9T73dchuDJRerRK1KiGX18aL16XAFXhGp8dRxcUC9DwXClDRXR.klqRnf2IB6Q1sYeSepPPnDsYDR5UejpA; path=/; expires=Thu, 26-Dec-24 22:40:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=l3nM_E6FJb0_cEFNaK2A3mH4Lnh.Mi1rO3YpAJngtGw-1735251005172-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f84661b6de42014-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:10:04,946 DEBUG: request_id: req_e632fa9c2a7cd5a02ee62ddc18f0050a [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:10:04,953 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:10:04,953 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:10:04,965 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:10:04,965 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:10:04,998 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:10:04,999 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:10:04,999 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:05,056 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e9d2f50> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:05,056 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12e97ce60> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:05,148 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e9d2fd0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:05,149 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:05,149 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:05,149 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:05,150 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:05,150 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:06,225 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:10:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'742'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'199288'), (b'x-ratelimit-reset-requests', b'55.589s'), (b'x-ratelimit-reset-tokens', b'213ms'), (b'x-request-id', b'req_469feb2a2594e497d64965693b8f65c1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ipOxERTdcSdgEjn5OCOU.cAByJO.g8dXAmmxqZA1JZI-1735251006-1.0.1.1-9Mef4KnjF3353do9XKlq38jkNFbhjImmXGfRS7o.W3QXolKGgRhdWYu0wvVyn1EO5FfvbKEfbvbUveisiR6srQ; path=/; expires=Thu, 26-Dec-24 22:40:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=TXqN8vMcInP_D_gEeVKo2ormksTksA5V0WWYAWs.wp8-1735251006362-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f8466201d7ea58a-SCL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:06,227 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:10:06,227 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:06,228 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:06,228 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:06,229 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:10:06,229 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:10:06 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '742'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9993'), ('x-ratelimit-remaining-tokens', '199288'), ('x-ratelimit-reset-requests', '55.589s'), ('x-ratelimit-reset-tokens', '213ms'), ('x-request-id', 'req_469feb2a2594e497d64965693b8f65c1'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=ipOxERTdcSdgEjn5OCOU.cAByJO.g8dXAmmxqZA1JZI-1735251006-1.0.1.1-9Mef4KnjF3353do9XKlq38jkNFbhjImmXGfRS7o.W3QXolKGgRhdWYu0wvVyn1EO5FfvbKEfbvbUveisiR6srQ; path=/; expires=Thu, 26-Dec-24 22:40:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=TXqN8vMcInP_D_gEeVKo2ormksTksA5V0WWYAWs.wp8-1735251006362-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f8466201d7ea58a-SCL'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:10:06,230 DEBUG: request_id: req_469feb2a2594e497d64965693b8f65c1 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:10:06,240 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 57, in generate_response
    response = invoke_our_graph(state)
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 24, in invoke_our_graph
    response = graph_runnable.invoke(state)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1535, in invoke
    for chunk in self.stream(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1273, in stream
    for _ in runner.tick(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/runner.py", line 56, in tick
    run_with_retry(t, retry_policy)
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/retry.py", line 29, in run_with_retry
    task.proc.invoke(task.input, config)
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 410, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 141, in invoke
    raise TypeError(
TypeError: No synchronous function provided to "save_memory".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2024-12-26 19:10:06,242 INFO: 127.0.0.1 - - [26/Dec/2024 19:10:06] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:13:35,607 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:13:35,610 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:13:35,629 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:35,629 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:35,629 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:35,630 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:35,630 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:35,631 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:35,631 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:35,631 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:35,677 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:13:35,680 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:13:35,704 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:13:35,705 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:13:35,706 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:35,967 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e9c9610> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:35,968 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12e97ca70> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:36,044 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e9c8150> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:36,044 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:36,045 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:36,045 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:36,046 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:36,046 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:36,841 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:13:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'202'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199677'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_a94d639c2b0a0c4df33ef29382f7d39c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=nu53RcxXccLFsbJLkw5EK5xbf3ezWJnO34YE3l.hofg-1735251217-1.0.1.1-_M.W5Ogx15eG8_lrJXtYilX74RtwNpvQxWkwqkAuwHU0xawJ6dknPkwkPMuDS3kwYbN_u55oheBr4NTl.5MWTA; path=/; expires=Thu, 26-Dec-24 22:43:37 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=X6e99UfUveQtaWj9WEWNkyYFHtt.VTSI_nCFAwLbyIE-1735251217091-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f846b465ed89b20-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:36,844 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:13:36,845 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:36,861 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:36,861 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:36,861 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:36,862 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:13:37 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '202'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199677'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '96ms'), ('x-request-id', 'req_a94d639c2b0a0c4df33ef29382f7d39c'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=nu53RcxXccLFsbJLkw5EK5xbf3ezWJnO34YE3l.hofg-1735251217-1.0.1.1-_M.W5Ogx15eG8_lrJXtYilX74RtwNpvQxWkwqkAuwHU0xawJ6dknPkwkPMuDS3kwYbN_u55oheBr4NTl.5MWTA; path=/; expires=Thu, 26-Dec-24 22:43:37 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=X6e99UfUveQtaWj9WEWNkyYFHtt.VTSI_nCFAwLbyIE-1735251217091-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f846b465ed89b20-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:13:36,863 DEBUG: request_id: req_a94d639c2b0a0c4df33ef29382f7d39c [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:13:36,874 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:13:36,874 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:13:36,887 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:13:36,887 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:13:36,929 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:13:36,929 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:13:36,930 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:36,990 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e9dc850> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:36,990 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12df9f770> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:37,078 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e9dc410> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:37,079 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:37,079 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:37,079 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:37,080 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:37,080 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:38,365 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:13:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'772'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199288'), (b'x-ratelimit-reset-requests', b'16.307s'), (b'x-ratelimit-reset-tokens', b'213ms'), (b'x-request-id', b'req_6486acd8bfbb495ab73414f3ea3471b4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.2lhf3aQGvgASR2HAA3DSufIJIb9igfrPtEoG5M7OOM-1735251218-1.0.1.1-a9sUqDp8bqdEqVkMtCG6bVoA_MbA1Dr5eC27xP0zfcPZ13Li9dvsHk0koirV8BqnxrJBlBvmkhNWi7r7tWKTbA; path=/; expires=Thu, 26-Dec-24 22:43:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=BiT0Mh6GPx6qVzRCYUfZOiZ7F9TjXzKtlEFc9ljw0lQ-1735251218624-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f846b4c9db69b12-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:38,367 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:13:38,367 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:38,368 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:38,368 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:38,368 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:38,369 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:13:38 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '772'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9998'), ('x-ratelimit-remaining-tokens', '199288'), ('x-ratelimit-reset-requests', '16.307s'), ('x-ratelimit-reset-tokens', '213ms'), ('x-request-id', 'req_6486acd8bfbb495ab73414f3ea3471b4'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=.2lhf3aQGvgASR2HAA3DSufIJIb9igfrPtEoG5M7OOM-1735251218-1.0.1.1-a9sUqDp8bqdEqVkMtCG6bVoA_MbA1Dr5eC27xP0zfcPZ13Li9dvsHk0koirV8BqnxrJBlBvmkhNWi7r7tWKTbA; path=/; expires=Thu, 26-Dec-24 22:43:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=BiT0Mh6GPx6qVzRCYUfZOiZ7F9TjXzKtlEFc9ljw0lQ-1735251218624-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f846b4c9db69b12-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:13:38,369 DEBUG: request_id: req_6486acd8bfbb495ab73414f3ea3471b4 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:13:38,383 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 57, in generate_response
    response = await invoke_our_graph(state)
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 24, in invoke_our_graph
    response = await graph_runnable.ainvoke(state)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1535, in invoke
    for chunk in self.stream(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1273, in stream
    for _ in runner.tick(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/runner.py", line 56, in tick
    run_with_retry(t, retry_policy)
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/retry.py", line 29, in run_with_retry
    task.proc.invoke(task.input, config)
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 410, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 141, in invoke
    raise TypeError(
TypeError: No synchronous function provided to "save_memory".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2024-12-26 19:13:38,390 INFO: 127.0.0.1 - - [26/Dec/2024 19:13:38] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:13:40,637 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:13:40,638 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:13:40,648 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:13:40,649 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:13:40,663 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:13:40,663 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:13:40,663 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:40,727 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e89aa10> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:40,727 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12e8f7770> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:40,835 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e9de510> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:40,835 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:40,836 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:40,836 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:40,836 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:40,836 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:41,746 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:13:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'253'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199677'), (b'x-ratelimit-reset-requests', b'21.139s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_f45040d8a3d9baccf03be0b908bbbffa'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=M1WugOI6ybCLHQfwbSx2Yb.jNcZ83T6rVXWNbAsfgGQ-1735251221-1.0.1.1-_tfyMN9eQ0OA12iSXItd0CZwAacllPHpa7N6fvuJhTFQ1vBNqEHYiLdQvnyz_nV1LlOKkgpoffFdxonj6kk1_w; path=/; expires=Thu, 26-Dec-24 22:43:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=LFkct25qgu13MRRPpLHk_FuV3w1Lv_BVSlpQuzgNcwA-1735251221918-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f846b646f458bc2-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:41,747 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:13:41,747 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:41,748 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:41,748 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:41,748 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:41,748 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:13:41 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '253'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9997'), ('x-ratelimit-remaining-tokens', '199677'), ('x-ratelimit-reset-requests', '21.139s'), ('x-ratelimit-reset-tokens', '96ms'), ('x-request-id', 'req_f45040d8a3d9baccf03be0b908bbbffa'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=M1WugOI6ybCLHQfwbSx2Yb.jNcZ83T6rVXWNbAsfgGQ-1735251221-1.0.1.1-_tfyMN9eQ0OA12iSXItd0CZwAacllPHpa7N6fvuJhTFQ1vBNqEHYiLdQvnyz_nV1LlOKkgpoffFdxonj6kk1_w; path=/; expires=Thu, 26-Dec-24 22:43:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=LFkct25qgu13MRRPpLHk_FuV3w1Lv_BVSlpQuzgNcwA-1735251221918-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f846b646f458bc2-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:13:41,749 DEBUG: request_id: req_f45040d8a3d9baccf03be0b908bbbffa [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:13:41,755 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:13:41,756 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:13:41,767 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:13:41,768 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:13:41,803 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:13:41,803 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:13:41,804 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:41,821 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e9b3650> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:41,821 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12e8f75c0> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:41,890 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e9b31d0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:41,890 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:41,891 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:41,891 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:41,891 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:41,891 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:43,153 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:13:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'951'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'199286'), (b'x-ratelimit-reset-requests', b'29.065s'), (b'x-ratelimit-reset-tokens', b'213ms'), (b'x-request-id', b'req_450b17f6ddfb186348aaed762f6c7b0b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=R9yjFyXY6pnnZpT8eU0aqRhrZS232oh2SCOL4YX79w4-1735251223-1.0.1.1-kzJWhARGaKWkIs.MtAFP47hloPPAjo2EVUtDu30xaIfX3cC5m_9z7_NCg.syhSVs6iwOkm.ejIe9tL3YYTbtjw; path=/; expires=Thu, 26-Dec-24 22:43:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=92OLJcuLj6o8ViHX.pBKhr37zAYnY5aneYjA7pLHHRQ-1735251223323-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f846b6abaf09b23-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:43,154 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:13:43,154 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:43,155 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:43,156 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:43,156 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:43,156 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:13:43 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '951'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9996'), ('x-ratelimit-remaining-tokens', '199286'), ('x-ratelimit-reset-requests', '29.065s'), ('x-ratelimit-reset-tokens', '213ms'), ('x-request-id', 'req_450b17f6ddfb186348aaed762f6c7b0b'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=R9yjFyXY6pnnZpT8eU0aqRhrZS232oh2SCOL4YX79w4-1735251223-1.0.1.1-kzJWhARGaKWkIs.MtAFP47hloPPAjo2EVUtDu30xaIfX3cC5m_9z7_NCg.syhSVs6iwOkm.ejIe9tL3YYTbtjw; path=/; expires=Thu, 26-Dec-24 22:43:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=92OLJcuLj6o8ViHX.pBKhr37zAYnY5aneYjA7pLHHRQ-1735251223323-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f846b6abaf09b23-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:13:43,157 DEBUG: request_id: req_450b17f6ddfb186348aaed762f6c7b0b [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:13:43,168 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 57, in generate_response
    response = await invoke_our_graph(state)
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 24, in invoke_our_graph
    response = await graph_runnable.ainvoke(state)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1535, in invoke
    for chunk in self.stream(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1273, in stream
    for _ in runner.tick(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/runner.py", line 56, in tick
    run_with_retry(t, retry_policy)
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/retry.py", line 29, in run_with_retry
    task.proc.invoke(task.input, config)
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 410, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 141, in invoke
    raise TypeError(
TypeError: No synchronous function provided to "save_memory".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2024-12-26 19:13:43,170 INFO: 127.0.0.1 - - [26/Dec/2024 19:13:43] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:13:45,757 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:13:45,759 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:13:45,770 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:13:45,770 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:13:45,785 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:13:45,786 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:13:45,786 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:45,828 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12ea05190> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:45,828 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12e8f6330> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:45,918 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e9b1cd0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:45,918 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:45,919 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:45,919 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:45,919 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:45,919 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,366 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:13:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'199'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'199677'), (b'x-ratelimit-reset-requests', b'33.668s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_e60de2f381d567391313f521066b66b9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=hNhqWjf0Qtn2g4kOlnbsUyvATrfGgQBc8Yyqjv7V0pU-1735251226-1.0.1.1-K.aVtOtFHgSIbVRtj6pBkXKyA5vjU1vRhoIqyO5dPtO494cyTN6lasT.U5aCAd7AFZrihgFiBxRAqc7IquP.zA; path=/; expires=Thu, 26-Dec-24 22:43:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=5hvi.JccieNKcOhAZiCKJD5sGy3pe8g9bXR8iZMjt.Y-1735251226612-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f846b83dd1da7a7-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,368 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:13:46,368 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,392 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,393 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,393 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,393 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:13:46 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '199'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9996'), ('x-ratelimit-remaining-tokens', '199677'), ('x-ratelimit-reset-requests', '33.668s'), ('x-ratelimit-reset-tokens', '96ms'), ('x-request-id', 'req_e60de2f381d567391313f521066b66b9'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=hNhqWjf0Qtn2g4kOlnbsUyvATrfGgQBc8Yyqjv7V0pU-1735251226-1.0.1.1-K.aVtOtFHgSIbVRtj6pBkXKyA5vjU1vRhoIqyO5dPtO494cyTN6lasT.U5aCAd7AFZrihgFiBxRAqc7IquP.zA; path=/; expires=Thu, 26-Dec-24 22:43:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=5hvi.JccieNKcOhAZiCKJD5sGy3pe8g9bXR8iZMjt.Y-1735251226612-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f846b83dd1da7a7-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:13:46,394 DEBUG: request_id: req_e60de2f381d567391313f521066b66b9 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:13:46,402 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:13:46,403 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:13:46,418 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,418 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,419 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,419 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,419 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,419 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,419 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,419 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,430 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:13:46,430 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:13:46,463 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:13:46,464 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:13:46,465 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,540 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x109be6510> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,541 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12e8f7bf0> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,644 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e8b8a90> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,645 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,645 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,645 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,645 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:46,646 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:47,970 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:13:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'970'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9995'), (b'x-ratelimit-remaining-tokens', b'199285'), (b'x-ratelimit-reset-requests', b'41.453s'), (b'x-ratelimit-reset-tokens', b'214ms'), (b'x-request-id', b'req_d535b8902de6b7e02d7006a5c6878cb0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ThyWEZaAD7nxpCowPiDkVyOWXXVoG7Eqf44F6z0dpNA-1735251228-1.0.1.1-P6lxXxRM..T38r7KDn_CBQOsYubwzMIHqtMcyGevdM4SlCcSwzCwhFQAp3tG.rnJht3ndoqiVkzggEBZQVLQrA; path=/; expires=Thu, 26-Dec-24 22:43:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=gJpA3oCoUQFxT.Z5SnoR73B3XpFmjbZaJRHBGg3KkO8-1735251228238-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f846b894ce19b17-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:47,971 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:13:47,972 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:47,983 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:47,983 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:47,983 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:47,983 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:13:48 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '970'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9995'), ('x-ratelimit-remaining-tokens', '199285'), ('x-ratelimit-reset-requests', '41.453s'), ('x-ratelimit-reset-tokens', '214ms'), ('x-request-id', 'req_d535b8902de6b7e02d7006a5c6878cb0'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=ThyWEZaAD7nxpCowPiDkVyOWXXVoG7Eqf44F6z0dpNA-1735251228-1.0.1.1-P6lxXxRM..T38r7KDn_CBQOsYubwzMIHqtMcyGevdM4SlCcSwzCwhFQAp3tG.rnJht3ndoqiVkzggEBZQVLQrA; path=/; expires=Thu, 26-Dec-24 22:43:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=gJpA3oCoUQFxT.Z5SnoR73B3XpFmjbZaJRHBGg3KkO8-1735251228238-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f846b894ce19b17-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:13:47,984 DEBUG: request_id: req_d535b8902de6b7e02d7006a5c6878cb0 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:13:47,992 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 57, in generate_response
    response = await invoke_our_graph(state)
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 24, in invoke_our_graph
    response = await graph_runnable.ainvoke(state)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1535, in invoke
    for chunk in self.stream(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1273, in stream
    for _ in runner.tick(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/runner.py", line 56, in tick
    run_with_retry(t, retry_policy)
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/retry.py", line 29, in run_with_retry
    task.proc.invoke(task.input, config)
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 410, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 141, in invoke
    raise TypeError(
TypeError: No synchronous function provided to "save_memory".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2024-12-26 19:13:47,994 INFO: 127.0.0.1 - - [26/Dec/2024 19:13:47] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:13:51,655 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:13:51,656 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:13:51,667 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:13:51,667 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:13:51,682 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:13:51,683 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:13:51,683 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:51,710 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e9ca090> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:51,711 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12df9f650> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:51,821 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12def4950> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:51,821 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:51,822 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:51,822 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:51,822 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:51,822 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:52,723 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:13:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'217'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'199678'), (b'x-ratelimit-reset-requests', b'44.677s'), (b'x-ratelimit-reset-tokens', b'96ms'), (b'x-request-id', b'req_3246b41a075cf3c518436638f28389c6'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Nc3DY2b.HBRkIkq8JFOQM2_Y7vhYvHM5m3PuJLdPnPY-1735251232-1.0.1.1-KKzf8OkgEdbS9RI26fVa_h4mfeMZ.aNrC8Ocyp6SICOFu0Oj54LuhmXnOBPpgZgesk6EArsjRhQA2eUPOPp7KQ; path=/; expires=Thu, 26-Dec-24 22:43:52 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=ddC.IGwCM3opGucix3ftVIp_3x3bx_0fP9fL4XpwqXs-1735251232900-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f846ba95ff59c11-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:52,724 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:13:52,725 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:52,725 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:52,726 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:52,726 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:52,726 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:13:52 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '217'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9994'), ('x-ratelimit-remaining-tokens', '199678'), ('x-ratelimit-reset-requests', '44.677s'), ('x-ratelimit-reset-tokens', '96ms'), ('x-request-id', 'req_3246b41a075cf3c518436638f28389c6'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Nc3DY2b.HBRkIkq8JFOQM2_Y7vhYvHM5m3PuJLdPnPY-1735251232-1.0.1.1-KKzf8OkgEdbS9RI26fVa_h4mfeMZ.aNrC8Ocyp6SICOFu0Oj54LuhmXnOBPpgZgesk6EArsjRhQA2eUPOPp7KQ; path=/; expires=Thu, 26-Dec-24 22:43:52 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=ddC.IGwCM3opGucix3ftVIp_3x3bx_0fP9fL4XpwqXs-1735251232900-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f846ba95ff59c11-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:13:52,727 DEBUG: request_id: req_3246b41a075cf3c518436638f28389c6 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:13:52,735 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:13:52,736 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:13:52,749 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:13:52,749 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:13:52,785 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:13:52,786 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:13:52,786 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:52,914 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e9d8d90> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:52,914 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12e8f7c80> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:53,123 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12e955850> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:53,123 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:53,124 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:53,124 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:53,125 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:53,125 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:54,849 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:13:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'1479'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'199282'), (b'x-ratelimit-reset-requests', b'52.384s'), (b'x-ratelimit-reset-tokens', b'215ms'), (b'x-request-id', b'req_01466fe74d5650286aa08b32ff2a1c27'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=QgO_JmcbOIvwOlcrkSDVGS6tcnhRd9E6o7PTUbyWPcI-1735251235-1.0.1.1-RNsMkS_Os.njyMpYerAIJnOEZZhWtfYD4tzrDza_Z_qSgPuMwOUS3qGyT31jhywIydIN7uqms3olgsRT5hOxaA; path=/; expires=Thu, 26-Dec-24 22:43:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=C5nuTF8CT3E884yRrECEmUmefOH8tphYuQfJxoMVyt4-1735251235104-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f846bb0ea61a789-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:54,851 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:13:54,852 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:54,867 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:54,867 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:54,867 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:13:54,867 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:13:55 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '1479'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9993'), ('x-ratelimit-remaining-tokens', '199282'), ('x-ratelimit-reset-requests', '52.384s'), ('x-ratelimit-reset-tokens', '215ms'), ('x-request-id', 'req_01466fe74d5650286aa08b32ff2a1c27'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=QgO_JmcbOIvwOlcrkSDVGS6tcnhRd9E6o7PTUbyWPcI-1735251235-1.0.1.1-RNsMkS_Os.njyMpYerAIJnOEZZhWtfYD4tzrDza_Z_qSgPuMwOUS3qGyT31jhywIydIN7uqms3olgsRT5hOxaA; path=/; expires=Thu, 26-Dec-24 22:43:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=C5nuTF8CT3E884yRrECEmUmefOH8tphYuQfJxoMVyt4-1735251235104-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f846bb0ea61a789-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:13:54,868 DEBUG: request_id: req_01466fe74d5650286aa08b32ff2a1c27 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:13:54,879 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 57, in generate_response
    response = await invoke_our_graph(state)
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 24, in invoke_our_graph
    response = await graph_runnable.ainvoke(state)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1535, in invoke
    for chunk in self.stream(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/__init__.py", line 1273, in stream
    for _ in runner.tick(
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/runner.py", line 56, in tick
    run_with_retry(t, retry_policy)
  File "/usr/local/lib/python3.11/site-packages/langgraph/pregel/retry.py", line 29, in run_with_retry
    task.proc.invoke(task.input, config)
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 410, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/langgraph/utils/runnable.py", line 141, in invoke
    raise TypeError(
TypeError: No synchronous function provided to "save_memory".
Either initialize with a synchronous function or invoke via the async API (ainvoke, astream, etc.)
2024-12-26 19:13:54,881 INFO: 127.0.0.1 - - [26/Dec/2024 19:13:54] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:14:09,592 DEBUG: Closing Client.session [in /usr/local/lib/python3.11/site-packages/langsmith/client.py:332]
2024-12-26 19:14:09,595 DEBUG: Closing Client.session [in /usr/local/lib/python3.11/site-packages/langsmith/client.py:332]
2024-12-26 19:14:10,076 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:10,077 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:10,077 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:10,077 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:10,077 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:10,078 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:10,078 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:10,078 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:10,078 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:10,078 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:10,079 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:10,079 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:10,079 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:10,079 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:10,079 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:10,080 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:10,080 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:10,080 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:14:13,436 INFO: Flask app started [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/run.py:26]
2024-12-26 19:14:13,475 INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.186:8000 [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:14:13,476 INFO: [33mPress CTRL+C to quit[0m [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:14:22,039 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:14:22,040 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:14:22,050 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:14:22,051 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:14:26,486 INFO: Discovering subpackages in _NamespacePath(['/usr/local/lib/python3.11/site-packages/pinecone_plugins']) [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_namespace_packages.py:12]
2024-12-26 19:14:26,487 INFO: Looking for plugins in pinecone_plugins.inference [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_plugins.py:9]
2024-12-26 19:14:26,518 INFO: Installing plugin inference into Pinecone [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/installation.py:10]
2024-12-26 19:14:27,460 DEBUG: response body: b'{"name":"jumbo-ai","metric":"dotproduct","dimension":512,"status":{"ready":true,"state":"Ready"},"host":"jumbo-ai-blg7rf2.svc.aped-4627-b74a.pinecone.io","spec":{"serverless":{"region":"us-east-1","cloud":"aws"}},"deletion_protection":"disabled"}' [in /usr/local/lib/python3.11/site-packages/pinecone/core/openapi/shared/rest.py:264]
2024-12-26 19:14:27,623 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:14:27,623 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:14:27,631 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:14:27,631 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:14:30,595 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 87, in process_whatsapp_message
    response = process_text_for_whatsapp(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 63, in process_text_for_whatsapp
    text = re.sub(pattern, "", text).strip()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 185, in sub
    return _compile(pattern, flags).sub(repl, string, count)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'coroutine'
2024-12-26 19:14:30,596 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 87, in process_whatsapp_message
    response = process_text_for_whatsapp(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 63, in process_text_for_whatsapp
    text = re.sub(pattern, "", text).strip()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 185, in sub
    return _compile(pattern, flags).sub(repl, string, count)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'coroutine'
2024-12-26 19:14:30,602 INFO: 127.0.0.1 - - [26/Dec/2024 19:14:30] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:14:30,605 INFO: 127.0.0.1 - - [26/Dec/2024 19:14:30] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:14:31,886 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 87, in process_whatsapp_message
    response = process_text_for_whatsapp(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 63, in process_text_for_whatsapp
    text = re.sub(pattern, "", text).strip()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 185, in sub
    return _compile(pattern, flags).sub(repl, string, count)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'coroutine'
2024-12-26 19:14:31,889 INFO: 127.0.0.1 - - [26/Dec/2024 19:14:31] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:14:32,777 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 87, in process_whatsapp_message
    response = process_text_for_whatsapp(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 63, in process_text_for_whatsapp
    text = re.sub(pattern, "", text).strip()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 185, in sub
    return _compile(pattern, flags).sub(repl, string, count)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'coroutine'
2024-12-26 19:14:32,780 INFO: 127.0.0.1 - - [26/Dec/2024 19:14:32] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:14:34,933 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 87, in process_whatsapp_message
    response = process_text_for_whatsapp(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 63, in process_text_for_whatsapp
    text = re.sub(pattern, "", text).strip()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 185, in sub
    return _compile(pattern, flags).sub(repl, string, count)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'coroutine'
2024-12-26 19:14:34,936 INFO: 127.0.0.1 - - [26/Dec/2024 19:14:34] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:15:01,395 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 87, in process_whatsapp_message
    response = process_text_for_whatsapp(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 63, in process_text_for_whatsapp
    text = re.sub(pattern, "", text).strip()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 185, in sub
    return _compile(pattern, flags).sub(repl, string, count)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'coroutine'
2024-12-26 19:15:01,413 INFO: 127.0.0.1 - - [26/Dec/2024 19:15:01] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:15:51,756 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 87, in process_whatsapp_message
    response = process_text_for_whatsapp(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 63, in process_text_for_whatsapp
    text = re.sub(pattern, "", text).strip()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 185, in sub
    return _compile(pattern, flags).sub(repl, string, count)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'coroutine'
2024-12-26 19:15:51,759 INFO: 127.0.0.1 - - [26/Dec/2024 19:15:51] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:15:52,622 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 87, in process_whatsapp_message
    response = process_text_for_whatsapp(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 63, in process_text_for_whatsapp
    text = re.sub(pattern, "", text).strip()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 185, in sub
    return _compile(pattern, flags).sub(repl, string, count)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'coroutine'
2024-12-26 19:15:52,625 INFO: 127.0.0.1 - - [26/Dec/2024 19:15:52] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:15:53,696 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 87, in process_whatsapp_message
    response = process_text_for_whatsapp(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 63, in process_text_for_whatsapp
    text = re.sub(pattern, "", text).strip()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 185, in sub
    return _compile(pattern, flags).sub(repl, string, count)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'coroutine'
2024-12-26 19:15:53,698 INFO: 127.0.0.1 - - [26/Dec/2024 19:15:53] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:15:56,032 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 87, in process_whatsapp_message
    response = process_text_for_whatsapp(response)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 63, in process_text_for_whatsapp
    text = re.sub(pattern, "", text).strip()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/re/__init__.py", line 185, in sub
    return _compile(pattern, flags).sub(repl, string, count)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'coroutine'
2024-12-26 19:15:56,035 INFO: 127.0.0.1 - - [26/Dec/2024 19:15:56] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:16:23,249 INFO: Flask app started [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/run.py:26]
2024-12-26 19:16:23,295 INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.186:8000 [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:16:23,295 INFO: [33mPress CTRL+C to quit[0m [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:16:26,021 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:16:26,021 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:16:26,032 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:16:26,032 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:16:30,377 INFO: Discovering subpackages in _NamespacePath(['/usr/local/lib/python3.11/site-packages/pinecone_plugins']) [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_namespace_packages.py:12]
2024-12-26 19:16:30,378 INFO: Looking for plugins in pinecone_plugins.inference [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_plugins.py:9]
2024-12-26 19:16:30,407 INFO: Installing plugin inference into Pinecone [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/installation.py:10]
2024-12-26 19:16:30,835 DEBUG: response body: b'{"name":"jumbo-ai","metric":"dotproduct","dimension":512,"status":{"ready":true,"state":"Ready"},"host":"jumbo-ai-blg7rf2.svc.aped-4627-b74a.pinecone.io","spec":{"serverless":{"region":"us-east-1","cloud":"aws"}},"deletion_protection":"disabled"}' [in /usr/local/lib/python3.11/site-packages/pinecone/core/openapi/shared/rest.py:264]
2024-12-26 19:16:30,914 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:16:30,915 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:16:30,924 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:16:30,924 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:16:34,725 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 57, in generate_response
    response =  invoke_our_graph(state)
                ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 27, in invoke_our_graph
    if "messages" in response and "cart" in response and "preferences" in response:
       ^^^^^^^^^^^^^^^^^^^^^^
TypeError: argument of type 'coroutine' is not iterable
2024-12-26 19:16:34,728 INFO: 127.0.0.1 - - [26/Dec/2024 19:16:34] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:17:17,610 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 57, in generate_response
    response =  invoke_our_graph(state)
                ^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 27, in invoke_our_graph
    if "messages" in response and "cart" in response and "preferences" in response:
       ^^^^^^^^^^^^^^^^^^^^^^
TypeError: argument of type 'coroutine' is not iterable
2024-12-26 19:17:17,619 INFO: 127.0.0.1 - - [26/Dec/2024 19:17:17] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:18:24,854 INFO: Flask app started [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/run.py:26]
2024-12-26 19:18:24,893 INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.186:8000 [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:18:24,893 INFO: [33mPress CTRL+C to quit[0m [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:18:39,225 INFO: 127.0.0.1 - - [26/Dec/2024 19:18:39] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:20:55,737 INFO: Flask app started [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/run.py:26]
2024-12-26 19:20:55,779 INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.186:8000 [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:20:55,779 INFO: [33mPress CTRL+C to quit[0m [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:21:03,471 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 883, in full_dispatch_request
    return self.finalize_request(rv)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 902, in finalize_request
    response = self.make_response(rv)
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1211, in make_response
    raise TypeError(
TypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a coroutine.
2024-12-26 19:21:03,477 INFO: 127.0.0.1 - - [26/Dec/2024 19:21:03] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:21:04,239 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 883, in full_dispatch_request
    return self.finalize_request(rv)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 902, in finalize_request
    response = self.make_response(rv)
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1211, in make_response
    raise TypeError(
TypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a coroutine.
2024-12-26 19:21:04,241 INFO: 127.0.0.1 - - [26/Dec/2024 19:21:04] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:21:04,314 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 883, in full_dispatch_request
    return self.finalize_request(rv)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 902, in finalize_request
    response = self.make_response(rv)
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1211, in make_response
    raise TypeError(
TypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a coroutine.
2024-12-26 19:21:04,315 INFO: 127.0.0.1 - - [26/Dec/2024 19:21:04] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:21:05,142 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 883, in full_dispatch_request
    return self.finalize_request(rv)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 902, in finalize_request
    response = self.make_response(rv)
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1211, in make_response
    raise TypeError(
TypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a coroutine.
2024-12-26 19:21:05,143 INFO: 127.0.0.1 - - [26/Dec/2024 19:21:05] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:21:07,229 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 883, in full_dispatch_request
    return self.finalize_request(rv)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 902, in finalize_request
    response = self.make_response(rv)
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1211, in make_response
    raise TypeError(
TypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a coroutine.
2024-12-26 19:21:07,230 INFO: 127.0.0.1 - - [26/Dec/2024 19:21:07] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:21:32,667 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 883, in full_dispatch_request
    return self.finalize_request(rv)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 902, in finalize_request
    response = self.make_response(rv)
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1211, in make_response
    raise TypeError(
TypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a coroutine.
2024-12-26 19:21:32,671 INFO: 127.0.0.1 - - [26/Dec/2024 19:21:32] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:21:36,153 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 883, in full_dispatch_request
    return self.finalize_request(rv)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 902, in finalize_request
    response = self.make_response(rv)
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1211, in make_response
    raise TypeError(
TypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a coroutine.
2024-12-26 19:21:36,160 INFO: 127.0.0.1 - - [26/Dec/2024 19:21:36] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:23:36,145 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 883, in full_dispatch_request
    return self.finalize_request(rv)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 902, in finalize_request
    response = self.make_response(rv)
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1211, in make_response
    raise TypeError(
TypeError: The view function did not return a valid response. The return type must be a string, dict, list, tuple with headers or status, Response instance, or WSGI callable, but it was a coroutine.
2024-12-26 19:23:36,151 INFO: 127.0.0.1 - - [26/Dec/2024 19:23:36] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:26:17,810 INFO: Flask app started [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/run.py:26]
2024-12-26 19:26:17,845 INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.186:8000 [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:26:17,846 INFO: [33mPress CTRL+C to quit[0m [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:26:28,407 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:26:28,407 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:26:28,418 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:26:28,418 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:26:34,156 INFO: Discovering subpackages in _NamespacePath(['/usr/local/lib/python3.11/site-packages/pinecone_plugins']) [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_namespace_packages.py:12]
2024-12-26 19:26:34,157 INFO: Looking for plugins in pinecone_plugins.inference [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_plugins.py:9]
2024-12-26 19:26:34,184 INFO: Installing plugin inference into Pinecone [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/installation.py:10]
2024-12-26 19:26:34,737 DEBUG: response body: b'{"name":"jumbo-ai","metric":"dotproduct","dimension":512,"status":{"ready":true,"state":"Ready"},"host":"jumbo-ai-blg7rf2.svc.aped-4627-b74a.pinecone.io","spec":{"serverless":{"region":"us-east-1","cloud":"aws"}},"deletion_protection":"disabled"}' [in /usr/local/lib/python3.11/site-packages/pinecone/core/openapi/shared/rest.py:264]
2024-12-26 19:26:35,000 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:26:35,001 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:26:35,016 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:26:35,016 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:26:40,437 DEBUG: Using selector: KqueueSelector [in /usr/local/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:54]
2024-12-26 19:26:40,516 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:26:40,517 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:26:40,526 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:26:40,527 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:26:40,547 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'soy vegan', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:26:40,548 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:26:40,548 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:40,647 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x127dd6890> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:40,647 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12894ac30> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:40,733 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12898e990> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:40,734 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:40,735 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:40,735 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:40,735 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:40,735 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:41,246 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:26:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'263'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199672'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'98ms'), (b'x-request-id', b'req_c7ce2c2fb894ed1c171525d39dd07c40'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=MShynH2sYqf8j2Ry.3i0D4oFSbOxuBzQLGvCF23kLP4-1735252001-1.0.1.1-.PsxWZv0V7PH0kXZT4UOSX_2V.KfaHG2AwfxrsA8j4ZaJ3jaVmFsTEz77v4DYBP69LUCCALDkjVHnhyUDYNtSw; path=/; expires=Thu, 26-Dec-24 22:56:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=C4MXuaoXvMfHuCpc0DdM2HCnpqdEO2_7HIy3bPLTVIM-1735252001552-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f847e6ee8749b1e-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:41,250 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:26:41,250 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:41,254 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:41,255 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:41,255 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:41,256 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:26:41 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '263'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199672'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '98ms'), ('x-request-id', 'req_c7ce2c2fb894ed1c171525d39dd07c40'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=MShynH2sYqf8j2Ry.3i0D4oFSbOxuBzQLGvCF23kLP4-1735252001-1.0.1.1-.PsxWZv0V7PH0kXZT4UOSX_2V.KfaHG2AwfxrsA8j4ZaJ3jaVmFsTEz77v4DYBP69LUCCALDkjVHnhyUDYNtSw; path=/; expires=Thu, 26-Dec-24 22:56:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=C4MXuaoXvMfHuCpc0DdM2HCnpqdEO2_7HIy3bPLTVIM-1735252001552-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f847e6ee8749b1e-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:26:41,257 DEBUG: request_id: req_c7ce2c2fb894ed1c171525d39dd07c40 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:26:41,291 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:26:41,292 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:26:41,302 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:26:41,302 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:26:41,334 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:41,334 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:41,343 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'soy vegan', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:26:41,344 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:26:41,344 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:41,405 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x127a25390> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:41,405 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12894a960> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:41,445 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1288e4f10> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:41,445 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:41,446 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:41,446 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:41,446 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:41,447 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:42,222 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:26:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'505'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199271'), (b'x-ratelimit-reset-requests', b'16.535s'), (b'x-ratelimit-reset-tokens', b'218ms'), (b'x-request-id', b'req_e08236a5cc7b9ab9f0d901b65c973cb1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=rFlhOtQp8QYHhGLz7kJheYwjQMKKDSGtOISS1AgEzDA-1735252002-1.0.1.1-.1BuZ3kL5MQjKwTcbK_f2HiQxAMUSofpCVxOsIq3kIdySYFSGdrbLq7YC0jzEFdAoh4KFXD_lLwtJAaibMKvpQ; path=/; expires=Thu, 26-Dec-24 22:56:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=GITaUjpChN48QMQS2a3LHvvxQHjUwxe0p00NHQjohXw-1735252002532-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f847e737e1c9b11-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:42,224 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:26:42,224 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:42,225 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:42,225 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:42,225 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:42,226 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:26:42 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '505'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9998'), ('x-ratelimit-remaining-tokens', '199271'), ('x-ratelimit-reset-requests', '16.535s'), ('x-ratelimit-reset-tokens', '218ms'), ('x-request-id', 'req_e08236a5cc7b9ab9f0d901b65c973cb1'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=rFlhOtQp8QYHhGLz7kJheYwjQMKKDSGtOISS1AgEzDA-1735252002-1.0.1.1-.1BuZ3kL5MQjKwTcbK_f2HiQxAMUSofpCVxOsIq3kIdySYFSGdrbLq7YC0jzEFdAoh4KFXD_lLwtJAaibMKvpQ; path=/; expires=Thu, 26-Dec-24 22:56:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=GITaUjpChN48QMQS2a3LHvvxQHjUwxe0p00NHQjohXw-1735252002532-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f847e737e1c9b11-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:26:42,227 DEBUG: request_id: req_e08236a5cc7b9ab9f0d901b65c973cb1 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:26:42,247 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:26:42,248 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:26:42,257 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:26:42,258 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:26:42,297 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'soy vegan', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_andOMFQWVHtEtYjEHRnyf7jS', 'function': {'name': 'save_to_memory', 'arguments': '{"user_id": "5491149276686", "content": "vegano", "context": "Preferencia diet\\u00e9tica del usuario"}'}}]}, {'content': 'vegano|Preferencia diet√©tica del usuario', 'role': 'tool', 'tool_call_id': 'call_andOMFQWVHtEtYjEHRnyf7jS'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:26:42,298 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:26:42,299 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:42,325 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x128a76a50> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:42,326 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12894b1d0> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:42,386 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1252820d0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:42,386 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:42,386 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:42,387 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:42,387 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:42,387 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:43,803 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:26:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'1135'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199258'), (b'x-ratelimit-reset-requests', b'24.258s'), (b'x-ratelimit-reset-tokens', b'222ms'), (b'x-request-id', b'req_a8cb833455509a4f16305f60c8f9311b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=UR6DUSL64v2jNydraxpPrnnoUIgn3tVrpc_YEshyX9Y-1735252004-1.0.1.1-la0gcKooXs9JkGf.WytG7a0pTzdpjVaSJ0Kg2fFGpLpGXGcY9zPaGdJLbU_kUEjxvPC7RcsByKyQGW1jvfNhOQ; path=/; expires=Thu, 26-Dec-24 22:56:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=qiJTy2cEiGbUK9dvySEAMc97H5HfaqW.pijBpLgbB8s-1735252004088-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f847e792e161ff5-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:43,804 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:26:43,805 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:43,806 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:43,806 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:43,806 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:26:43,806 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:26:44 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '1135'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9997'), ('x-ratelimit-remaining-tokens', '199258'), ('x-ratelimit-reset-requests', '24.258s'), ('x-ratelimit-reset-tokens', '222ms'), ('x-request-id', 'req_a8cb833455509a4f16305f60c8f9311b'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=UR6DUSL64v2jNydraxpPrnnoUIgn3tVrpc_YEshyX9Y-1735252004-1.0.1.1-la0gcKooXs9JkGf.WytG7a0pTzdpjVaSJ0Kg2fFGpLpGXGcY9zPaGdJLbU_kUEjxvPC7RcsByKyQGW1jvfNhOQ; path=/; expires=Thu, 26-Dec-24 22:56:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=qiJTy2cEiGbUK9dvySEAMc97H5HfaqW.pijBpLgbB8s-1735252004088-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f847e792e161ff5-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:26:43,807 DEBUG: request_id: req_a8cb833455509a4f16305f60c8f9311b [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:26:45,453 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 19:26:45,454 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 19:26:45,454 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkU5NThGOTM0MzREQTc2RjdBQwA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 19:26:45,455 INFO: 127.0.0.1 - - [26/Dec/2024 19:26:45] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:26:46,100 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:26:46,101 INFO: 127.0.0.1 - - [26/Dec/2024 19:26:46] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:26:46,929 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:26:46,930 INFO: 127.0.0.1 - - [26/Dec/2024 19:26:46] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:26:46,932 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:26:46,932 INFO: 127.0.0.1 - - [26/Dec/2024 19:26:46] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:27:04,198 DEBUG: Using selector: KqueueSelector [in /usr/local/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:54]
2024-12-26 19:27:04,210 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:27:04,211 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:27:04,221 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:27:04,221 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:27:04,236 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'soy vegano', 'role': 'user'}, {'content': '¬°Genial, gracias por compartirlo! He guardado que eres vegano. \n\nAhora, me gustar√≠a saber si tienes alguna alergia o restricci√≥n alimentaria que deba tener en cuenta al hacer tus recomendaciones. ¬øHay alg√∫n alimento espec√≠fico que debas evitar?', 'role': 'assistant'}, {'content': 'no me gusta la manzana', 'role': 'user'}, {'content': 'no me gusta la manzana', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:27:04,237 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:27:04,237 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,258 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x128644990> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,258 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12894a840> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,337 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x128992f50> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,337 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,338 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,338 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,338 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,338 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,908 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:27:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'311'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199606'), (b'x-ratelimit-reset-requests', b'10.934s'), (b'x-ratelimit-reset-tokens', b'118ms'), (b'x-request-id', b'req_1eccb18de1aec5f75ce8dd1a5fb2b75f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=UkKmZWwVxShVv6EnFUZNCqgVjTFt6b1TzvqOdL4Nmmo-1735252025-1.0.1.1-sWSqCPt.a13txYKoRXFHN91dX3cWlgI4u0B5e56fAmcTcFx.aMsBckWTtXntO9zq4d47RoaQqlTfksyWe3kn.A; path=/; expires=Thu, 26-Dec-24 22:57:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=kmU5ZlunVPyRAvIQ9zbztq9j4x2aGFZvFaalc3WlpY8-1735252025222-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f847f0279629c0f-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,909 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:27:04,910 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,914 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,915 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,915 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,915 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:27:05 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '311'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9998'), ('x-ratelimit-remaining-tokens', '199606'), ('x-ratelimit-reset-requests', '10.934s'), ('x-ratelimit-reset-tokens', '118ms'), ('x-request-id', 'req_1eccb18de1aec5f75ce8dd1a5fb2b75f'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=UkKmZWwVxShVv6EnFUZNCqgVjTFt6b1TzvqOdL4Nmmo-1735252025-1.0.1.1-sWSqCPt.a13txYKoRXFHN91dX3cWlgI4u0B5e56fAmcTcFx.aMsBckWTtXntO9zq4d47RoaQqlTfksyWe3kn.A; path=/; expires=Thu, 26-Dec-24 22:57:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=kmU5ZlunVPyRAvIQ9zbztq9j4x2aGFZvFaalc3WlpY8-1735252025222-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f847f0279629c0f-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:27:04,916 DEBUG: request_id: req_1eccb18de1aec5f75ce8dd1a5fb2b75f [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:27:04,926 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:27:04,927 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:27:04,939 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:27:04,940 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:27:04,961 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,961 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,961 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,961 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:04,983 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'soy vegan', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': '¬°Genial, gracias por compartirlo! He guardado que eres vegano. \n\nAhora, me gustar√≠a saber si tienes alguna alergia o restricci√≥n alimentaria que deba tener en cuenta al hacer tus recomendaciones. ¬øHay alg√∫n alimento espec√≠fico que debas evitar?', 'role': 'assistant'}, {'content': 'no me gusta la manzana', 'role': 'user'}, {'content': 'no me gusta la manzana', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:27:04,984 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:27:04,984 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:05,034 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1289c44d0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:05,035 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12894b920> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:05,098 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104554850> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:05,099 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:05,099 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:05,099 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:05,099 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:05,100 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:07,132 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:27:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'1820'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199198'), (b'x-ratelimit-reset-requests', b'18.843s'), (b'x-ratelimit-reset-tokens', b'240ms'), (b'x-request-id', b'req_51d9ffac11bb4fb95d163ad028a38477'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=2w8wzYiMPBhikP3.xObcpUt5o_3ypQJZ8jaqTBa5Q0U-1735252027-1.0.1.1-k0eSgqcXGkaW8nyXk3oRlSDOE8M8f9EKhGlpaftiue5SPyTgZQaHF3.O.81MU9eMXE2rR1PLg4rq1KeF7YwcEQ; path=/; expires=Thu, 26-Dec-24 22:57:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=p3dte6BgKpCHpIy6OkkdEAk5gG7J8o39wQeSG8pyIWU-1735252027442-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f847f072ffdb530-SCL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:07,134 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:27:07,134 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:07,153 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:07,154 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:07,154 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:07,155 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:27:07 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '1820'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9997'), ('x-ratelimit-remaining-tokens', '199198'), ('x-ratelimit-reset-requests', '18.843s'), ('x-ratelimit-reset-tokens', '240ms'), ('x-request-id', 'req_51d9ffac11bb4fb95d163ad028a38477'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=2w8wzYiMPBhikP3.xObcpUt5o_3ypQJZ8jaqTBa5Q0U-1735252027-1.0.1.1-k0eSgqcXGkaW8nyXk3oRlSDOE8M8f9EKhGlpaftiue5SPyTgZQaHF3.O.81MU9eMXE2rR1PLg4rq1KeF7YwcEQ; path=/; expires=Thu, 26-Dec-24 22:57:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=p3dte6BgKpCHpIy6OkkdEAk5gG7J8o39wQeSG8pyIWU-1735252027442-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f847f072ffdb530-SCL'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:27:07,155 DEBUG: request_id: req_51d9ffac11bb4fb95d163ad028a38477 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:27:07,177 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:27:07,178 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:27:07,188 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:27:07,188 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:27:07,229 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'soy vegan', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': '¬°Genial, gracias por compartirlo! He guardado que eres vegano. \n\nAhora, me gustar√≠a saber si tienes alguna alergia o restricci√≥n alimentaria que deba tener en cuenta al hacer tus recomendaciones. ¬øHay alg√∫n alimento espec√≠fico que debas evitar?', 'role': 'assistant'}, {'content': 'no me gusta la manzana', 'role': 'user'}, {'content': 'no me gusta la manzana', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_xpX5dFuTvJtO3JaoqVoJ2ZJD', 'function': {'name': 'save_to_memory', 'arguments': '{"user_id": "5491149276686", "content": "No le gusta la manzana", "context": "Preferencia alimentaria, alimentos que no le gustan."}'}}, {'type': 'function', 'id': 'call_WN0G2F5zhMUMcFKdoXNXewiE', 'function': {'name': 'save_to_memory', 'arguments': '{"user_id": "5491149276686", "content": "Es vegano", "context": "Preferencia diet\\u00e9tica."}'}}]}, {'content': 'No le gusta la manzana|Preferencia alimentaria, alimentos que no le gustan.', 'role': 'tool', 'tool_call_id': 'call_xpX5dFuTvJtO3JaoqVoJ2ZJD'}, {'content': 'Es vegano|Preferencia diet√©tica.', 'role': 'tool', 'tool_call_id': 'call_WN0G2F5zhMUMcFKdoXNXewiE'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:27:07,230 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:27:07,230 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:07,250 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x129294e90> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:07,251 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12894b1d0> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:07,304 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12863eb90> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:07,305 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:07,305 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:07,306 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:07,307 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:07,309 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:08,614 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:27:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'735'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199168'), (b'x-ratelimit-reset-requests', b'24.999s'), (b'x-ratelimit-reset-tokens', b'249ms'), (b'x-request-id', b'req_8da494c25f9aa834bcba4886498c5328'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=h28bBuYzWfWjFewAzSOeEW8wOAZYeIiWZ7FNWN8BylY-1735252028-1.0.1.1-Fum9hP.7_uSurdq.Rux6zPaaTh0KlC0cTWzRmuq88icUjsx25XG8YJ.227E096vy.ZIgwsU2dWReGohs2Z9kew; path=/; expires=Thu, 26-Dec-24 22:57:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=29O_IW413X3I1ETRfDahgdl2nGc3oBiADzeJ4rU_18o-1735252028862-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f847f14dcfe9c11-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:08,617 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:27:08,617 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:08,618 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:08,618 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:08,618 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:27:08,619 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:27:08 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '735'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9997'), ('x-ratelimit-remaining-tokens', '199168'), ('x-ratelimit-reset-requests', '24.999s'), ('x-ratelimit-reset-tokens', '249ms'), ('x-request-id', 'req_8da494c25f9aa834bcba4886498c5328'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=h28bBuYzWfWjFewAzSOeEW8wOAZYeIiWZ7FNWN8BylY-1735252028-1.0.1.1-Fum9hP.7_uSurdq.Rux6zPaaTh0KlC0cTWzRmuq88icUjsx25XG8YJ.227E096vy.ZIgwsU2dWReGohs2Z9kew; path=/; expires=Thu, 26-Dec-24 22:57:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=29O_IW413X3I1ETRfDahgdl2nGc3oBiADzeJ4rU_18o-1735252028862-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f847f14dcfe9c11-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:27:08,619 DEBUG: request_id: req_8da494c25f9aa834bcba4886498c5328 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:27:10,745 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 19:27:10,745 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 19:27:10,746 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjIxMUQzMEQxNDExNUQ4NDREMgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 19:27:10,747 INFO: 127.0.0.1 - - [26/Dec/2024 19:27:10] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:27:11,176 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:27:11,177 INFO: 127.0.0.1 - - [26/Dec/2024 19:27:11] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:27:11,826 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:27:11,826 INFO: 127.0.0.1 - - [26/Dec/2024 19:27:11] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:27:17,594 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:27:17,595 INFO: 127.0.0.1 - - [26/Dec/2024 19:27:17] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:28:40,207 DEBUG: Using selector: KqueueSelector [in /usr/local/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:54]
2024-12-26 19:28:40,233 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:28:40,235 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:28:40,253 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:28:40,254 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:28:40,275 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'no me gusta la manzana', 'role': 'user'}, {'content': 'He guardado que no te gusta la manzana y que eres vegano. \n\nAhora, para entender mejor tus h√°bitos de compra, ¬øpuedes decirme cu√°ntas personas hay en tu familia o cu√°ntas compras sueles hacer? Esto me ayudar√° a sugerirte las cantidades adecuadas.', 'role': 'assistant'}, {'content': 'vivo con mi pareja', 'role': 'user'}, {'content': 'vivo con mi pareja', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:28:40,276 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:28:40,277 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:40,449 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1285b7250> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:40,449 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12894ba40> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:40,518 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x128986cd0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:40,519 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:40,521 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:40,521 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:40,521 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:40,521 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:41,046 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:28:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'308'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'199605'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'118ms'), (b'x-request-id', b'req_6594674fc2f10ea24b46322e73963d19'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dBeuLDMCmLv3L8ut.vytRRsQpy4MbngQGpeV7vJ8RBs-1735252121-1.0.1.1-15sPt5xhxfWMuVX4DlAqd8El9UJPH_DTRm18I80ZynhTJMbtF4cEMyOVDqpkqKnz5LJpsrN.PIEf44wFmpYr0g; path=/; expires=Thu, 26-Dec-24 22:58:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=tGzq7gr8Ifv1iCamikjMDnQ_jK0EBG3egSi4yJ8ts_I-1735252121363-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f84815b7b489b1d-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:41,050 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:28:41,051 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:41,052 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:41,052 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:41,052 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:41,053 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:28:41 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '308'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '199605'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '118ms'), ('x-request-id', 'req_6594674fc2f10ea24b46322e73963d19'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=dBeuLDMCmLv3L8ut.vytRRsQpy4MbngQGpeV7vJ8RBs-1735252121-1.0.1.1-15sPt5xhxfWMuVX4DlAqd8El9UJPH_DTRm18I80ZynhTJMbtF4cEMyOVDqpkqKnz5LJpsrN.PIEf44wFmpYr0g; path=/; expires=Thu, 26-Dec-24 22:58:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=tGzq7gr8Ifv1iCamikjMDnQ_jK0EBG3egSi4yJ8ts_I-1735252121363-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f84815b7b489b1d-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:28:41,053 DEBUG: request_id: req_6594674fc2f10ea24b46322e73963d19 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:28:41,065 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:28:41,066 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:28:41,076 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:28:41,077 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:28:41,122 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'soy vegan', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': '¬°Genial, gracias por compartirlo! He guardado que eres vegano. \n\nAhora, me gustar√≠a saber si tienes alguna alergia o restricci√≥n alimentaria que deba tener en cuenta al hacer tus recomendaciones. ¬øHay alg√∫n alimento espec√≠fico que debas evitar?', 'role': 'assistant'}, {'content': 'no me gusta la manzana', 'role': 'user'}, {'content': 'He guardado que no te gusta la manzana y que eres vegano. \n\nAhora, para entender mejor tus h√°bitos de compra, ¬øpuedes decirme cu√°ntas personas hay en tu familia o cu√°ntas compras sueles hacer? Esto me ayudar√° a sugerirte las cantidades adecuadas.', 'role': 'assistant'}, {'content': 'vivo con mi pareja', 'role': 'user'}, {'content': 'vivo con mi pareja', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:28:41,123 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:28:41,123 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:41,166 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12926d110> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:41,166 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12894ac30> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:41,230 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12926d250> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:41,230 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:41,231 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:41,231 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:41,231 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:41,231 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,012 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:28:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'1581'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'199130'), (b'x-ratelimit-reset-requests', b'16.579s'), (b'x-ratelimit-reset-tokens', b'261ms'), (b'x-request-id', b'req_c451c8adc263606ca5eacd13c8170d45'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=nJ1rvi8ddlZlIj85JYdpYSGYiuaZ5fm_k8cEHCVhpdg-1735252123-1.0.1.1-pJ9Z.Yg6qdTldpcAAjgqIgz9m1L_xicZjLDr9oT2QvvLhp2lAbKEujnB9PMnAtwf8TknJpsIsKcW1DoqlxHqSw; path=/; expires=Thu, 26-Dec-24 22:58:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=r3.s59l3ztFG1bkZ8Jck9rjwT73LXsZprhZ84k8WIwA-1735252123331-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f84815ffc66e9ba-SCL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,014 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:28:43,014 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,015 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,015 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,015 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,015 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:28:43 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '1581'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9998'), ('x-ratelimit-remaining-tokens', '199130'), ('x-ratelimit-reset-requests', '16.579s'), ('x-ratelimit-reset-tokens', '261ms'), ('x-request-id', 'req_c451c8adc263606ca5eacd13c8170d45'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=nJ1rvi8ddlZlIj85JYdpYSGYiuaZ5fm_k8cEHCVhpdg-1735252123-1.0.1.1-pJ9Z.Yg6qdTldpcAAjgqIgz9m1L_xicZjLDr9oT2QvvLhp2lAbKEujnB9PMnAtwf8TknJpsIsKcW1DoqlxHqSw; path=/; expires=Thu, 26-Dec-24 22:58:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=r3.s59l3ztFG1bkZ8Jck9rjwT73LXsZprhZ84k8WIwA-1735252123331-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f84815ffc66e9ba-SCL'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:28:43,016 DEBUG: request_id: req_c451c8adc263606ca5eacd13c8170d45 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:28:43,029 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,030 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,030 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,030 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,030 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,030 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,066 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:28:43,066 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:28:43,074 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:28:43,074 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:28:43,115 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'soy vegan', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': '¬°Genial, gracias por compartirlo! He guardado que eres vegano. \n\nAhora, me gustar√≠a saber si tienes alguna alergia o restricci√≥n alimentaria que deba tener en cuenta al hacer tus recomendaciones. ¬øHay alg√∫n alimento espec√≠fico que debas evitar?', 'role': 'assistant'}, {'content': 'no me gusta la manzana', 'role': 'user'}, {'content': 'He guardado que no te gusta la manzana y que eres vegano. \n\nAhora, para entender mejor tus h√°bitos de compra, ¬øpuedes decirme cu√°ntas personas hay en tu familia o cu√°ntas compras sueles hacer? Esto me ayudar√° a sugerirte las cantidades adecuadas.', 'role': 'assistant'}, {'content': 'vivo con mi pareja', 'role': 'user'}, {'content': 'vivo con mi pareja', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_VnvJJM09rEVdxPvOssKA1UPE', 'function': {'name': 'save_to_memory', 'arguments': '{"user_id": "5491149276686", "content": "Vivo con mi pareja", "context": "Informaci\\u00f3n sobre el tama\\u00f1o de la familia del usuario."}'}}, {'type': 'function', 'id': 'call_NrWZWjDvQvYOdjQMVKNIRZzv', 'function': {'name': 'save_to_memory', 'arguments': '{"user_id": "5491149276686", "content": "Soy vegano", "context": "Preferencia diet\\u00e9tica del usuario."}'}}, {'type': 'function', 'id': 'call_F6ERlT0CBVHVhbXWdzBKcNZl', 'function': {'name': 'save_to_memory', 'arguments': '{"user_id": "5491149276686", "content": "No le gusta la manzana", "context": "Alimento que el usuario no disfruta."}'}}]}, {'content': 'Vivo con mi pareja|Informaci√≥n sobre el tama√±o de la familia del usuario.', 'role': 'tool', 'tool_call_id': 'call_VnvJJM09rEVdxPvOssKA1UPE'}, {'content': 'Soy vegano|Preferencia diet√©tica del usuario.', 'role': 'tool', 'tool_call_id': 'call_NrWZWjDvQvYOdjQMVKNIRZzv'}, {'content': 'No le gusta la manzana|Alimento que el usuario no disfruta.', 'role': 'tool', 'tool_call_id': 'call_F6ERlT0CBVHVhbXWdzBKcNZl'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:28:43,116 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:28:43,117 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,142 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x128a9f690> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,142 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12894b650> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,181 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x127ab3190> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,181 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,182 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,183 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,183 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,183 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,338 DEBUG: Using selector: KqueueSelector [in /usr/local/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/selector_events.py:54]
2024-12-26 19:28:43,351 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:28:43,352 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:28:43,363 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:28:43,363 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:28:43,379 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '    \n   Tu √∫nica funci√≥n es decidir si el usuario necesita configurar preferencias o hacer compras.\n    \n    DEBES RESPONDER √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "long" (preferencias a largo plazo)\n    - "shopping" (proceso de compra)\n    \n    REGLAS:\n    Responde "long" si:\n    - Es una conversaci√≥n nueva\n    - El usuario quiere configurar preferencias\n    - Menciona informaci√≥n personal nueva\n    - Menciona restricciones o alergias\n    - Falta informaci√≥n del usuario\n    - SI el usuario quiere agregar productos al carrito, RESPONDE shopping SIEMPRE!\n    \n    Responde "shopping" si:\n    - El usuario menciona productos espec√≠ficos\n    - Solicita buscar o agregar productos al carrito\n    - Quiere modificar cantidades en el carrito\n    - Ya est√° en proceso activo de compra\n    - El usuario necesita ayuda o sugerencias de compra  \n    - el usuario quiere agregar, borrar modificar productos de su carrito\n    \n    si el usuario no sabe que hacer, siempre debes ir al shopping asi el ai shopping le hace preguntas y lo asiste\n    NO AGREGUES NING√öN OTRO TEXTO O EXPLICACI√ìN.\n    RESPONDE √öNICAMENTE CON UNA DE ESTAS PALABRAS:\n    - "shopping"\n    - "long"\n    ', 'role': 'system'}, {'content': 'He guardado que no te gusta la manzana y que eres vegano. \n\nAhora, para entender mejor tus h√°bitos de compra, ¬øpuedes decirme cu√°ntas personas hay en tu familia o cu√°ntas compras sueles hacer? Esto me ayudar√° a sugerirte las cantidades adecuadas.', 'role': 'assistant'}, {'content': 'vivo con mi pareja', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'determine_next_node'}}, 'tools': [{'type': 'function', 'function': {'name': 'determine_next_node', 'description': 'Determine which node to proceed to based on the conversation', 'parameters': {'type': 'object', 'properties': {'decision': {'type': 'string', 'enum': ['shopping', 'long'], 'description': 'The next node to proceed to'}}, 'required': ['decision']}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:28:43,380 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:28:43,380 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,396 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x129324390> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,396 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x1292b9130> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,428 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x129324450> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,429 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,429 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,429 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,429 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,430 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,887 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:28:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'227'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'199610'), (b'x-ratelimit-reset-requests', b'22.994s'), (b'x-ratelimit-reset-tokens', b'117ms'), (b'x-request-id', b'req_34d96edad7e8c821d986db4c213d1c03'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=TLOkZWib.KIkmdyUoTfJHgOYdkdi6zLirT60ma6NVmA-1735252124-1.0.1.1-8feT8HCvEJVagJOTbZR7dvuEOLgclMnkNgOKwq8y5c.xZkpOmyLrNb46snY47CdHeeCms3dqslxSX8KixVClBw; path=/; expires=Thu, 26-Dec-24 22:58:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=Jc99Hy8k2FMq8KlahCM4EiM4judnON3_pH9ItPEcnIg-1735252124215-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f84816dad79c18c-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,887 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:28:43,887 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,888 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,888 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,888 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:43,888 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:28:44 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '227'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9997'), ('x-ratelimit-remaining-tokens', '199610'), ('x-ratelimit-reset-requests', '22.994s'), ('x-ratelimit-reset-tokens', '117ms'), ('x-request-id', 'req_34d96edad7e8c821d986db4c213d1c03'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=TLOkZWib.KIkmdyUoTfJHgOYdkdi6zLirT60ma6NVmA-1735252124-1.0.1.1-8feT8HCvEJVagJOTbZR7dvuEOLgclMnkNgOKwq8y5c.xZkpOmyLrNb46snY47CdHeeCms3dqslxSX8KixVClBw; path=/; expires=Thu, 26-Dec-24 22:58:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=Jc99Hy8k2FMq8KlahCM4EiM4judnON3_pH9ItPEcnIg-1735252124215-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f84816dad79c18c-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:28:43,888 DEBUG: request_id: req_34d96edad7e8c821d986db4c213d1c03 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:28:43,892 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:28:43,892 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:28:43,999 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:28:44,011 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:28:44,123 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'soy vegan', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': '¬°Genial, gracias por compartirlo! He guardado que eres vegano. \n\nAhora, me gustar√≠a saber si tienes alguna alergia o restricci√≥n alimentaria que deba tener en cuenta al hacer tus recomendaciones. ¬øHay alg√∫n alimento espec√≠fico que debas evitar?', 'role': 'assistant'}, {'content': 'no me gusta la manzana', 'role': 'user'}, {'content': 'He guardado que no te gusta la manzana y que eres vegano. \n\nAhora, para entender mejor tus h√°bitos de compra, ¬øpuedes decirme cu√°ntas personas hay en tu familia o cu√°ntas compras sueles hacer? Esto me ayudar√° a sugerirte las cantidades adecuadas.', 'role': 'assistant'}, {'content': 'vivo con mi pareja', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:28:44,142 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:28:44,143 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:44,238 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x128ab1050> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:44,239 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x1292b92e0> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:44,294 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x129327e50> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:44,294 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:44,294 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:44,294 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:44,296 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:44,298 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:44,558 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:28:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'741'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'199081'), (b'x-ratelimit-reset-requests', b'31.476s'), (b'x-ratelimit-reset-tokens', b'275ms'), (b'x-request-id', b'req_554aed8f0dcdff28b4c84fa92f7b51dd'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=jnSntWkz3IjkcTS2xK7_SlpBzR0FXohG_4yokQ7fXFI-1735252124-1.0.1.1-Ei5T0agX_WObCP8l0Yij72dGM3RND0wHTcS7FTzn0K2e19xmMvgkj1bC5ChZz4QnnJHRUnP6BNt7RBVi7amMZQ; path=/; expires=Thu, 26-Dec-24 22:58:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=Da0Xh_3QelSIpcqKlyE9f9zkxaiDWv6zIBwYXNLCaZM-1735252124888-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f84816c1ca59b1a-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:44,559 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:28:44,559 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:44,560 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:44,560 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:44,560 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:44,560 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:28:44 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '741'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9996'), ('x-ratelimit-remaining-tokens', '199081'), ('x-ratelimit-reset-requests', '31.476s'), ('x-ratelimit-reset-tokens', '275ms'), ('x-request-id', 'req_554aed8f0dcdff28b4c84fa92f7b51dd'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=jnSntWkz3IjkcTS2xK7_SlpBzR0FXohG_4yokQ7fXFI-1735252124-1.0.1.1-Ei5T0agX_WObCP8l0Yij72dGM3RND0wHTcS7FTzn0K2e19xmMvgkj1bC5ChZz4QnnJHRUnP6BNt7RBVi7amMZQ; path=/; expires=Thu, 26-Dec-24 22:58:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=Da0Xh_3QelSIpcqKlyE9f9zkxaiDWv6zIBwYXNLCaZM-1735252124888-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f84816c1ca59b1a-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:28:44,560 DEBUG: request_id: req_554aed8f0dcdff28b4c84fa92f7b51dd [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:28:45,650 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:28:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'1149'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9995'), (b'x-ratelimit-remaining-tokens', b'199128'), (b'x-ratelimit-reset-requests', b'39.42s'), (b'x-ratelimit-reset-tokens', b'261ms'), (b'x-request-id', b'req_752bb0db8a0609eaa465606a7e967025'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=2OnROlBOrR1u5JPU64KrRkIG609KGXIVrgVs9XZTkGU-1735252125-1.0.1.1-RCYIDRQoUMxIHy12W.BpQ9byJmqwSi6YZBv7njy1yCldUH.O4FPls5aYbLv89CiNEX9hT6XGvGiNFpAL_En5Ag; path=/; expires=Thu, 26-Dec-24 22:58:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=_KdH402qZ6NPaIYl5OcjqBYv7U9hBRcE3sz8FOhRn90-1735252125971-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f8481731bd3e9b8-SCL'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,652 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:28:45,652 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,653 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,653 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,653 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,654 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:28:45 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '1149'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9995'), ('x-ratelimit-remaining-tokens', '199128'), ('x-ratelimit-reset-requests', '39.42s'), ('x-ratelimit-reset-tokens', '261ms'), ('x-request-id', 'req_752bb0db8a0609eaa465606a7e967025'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=2OnROlBOrR1u5JPU64KrRkIG609KGXIVrgVs9XZTkGU-1735252125-1.0.1.1-RCYIDRQoUMxIHy12W.BpQ9byJmqwSi6YZBv7njy1yCldUH.O4FPls5aYbLv89CiNEX9hT6XGvGiNFpAL_En5Ag; path=/; expires=Thu, 26-Dec-24 22:58:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=_KdH402qZ6NPaIYl5OcjqBYv7U9hBRcE3sz8FOhRn90-1735252125971-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f8481731bd3e9b8-SCL'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:28:45,655 DEBUG: request_id: req_752bb0db8a0609eaa465606a7e967025 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:28:45,674 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:28:45,675 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:28:45,685 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,685 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,685 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,686 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,686 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,686 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,693 DEBUG: load_ssl_context verify=True cert=None trust_env=True http2=False [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:80]
2024-12-26 19:28:45,693 DEBUG: load_verify_locations cafile='/usr/local/lib/python3.11/site-packages/certifi/cacert.pem' [in /usr/local/lib/python3.11/site-packages/httpx/_config.py:146]
2024-12-26 19:28:45,734 DEBUG: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': '\n    Eres uno de los dos asistentes AI que trabajan juntos en frizbee para ayudar en el proceso de compras en el supermercado jumbo.\n    Tu √∫nica funci√≥n es recolectar y guardar las preferencias del usuario de manera proactiva. No debes realizar ninguna otra tarea.\n\n    El user_id del usuario es 5491149276686\n\n    OBJETIVO:\n    - Explicarle al usuario que es frizbee\n    - Recolectar informaci√≥n relevante sobre preferencias de compra\n    - Guardar cada preferencia importante usando la herramienta save_to_memory\n    - Mantener una conversaci√≥n natural y amigable\n    \n    INFORMACI√ìN A RECOLECTAR:\n    - Preferencias diet√©ticas (vegetariano, vegano, etc.)\n    - Alergias o restricciones alimentarias\n    - Tama√±o de familia/cantidad usual de compras\n    - Recetas habituales\n    - Postres favoritos\n    - desayuno habitual\n    - Cualquier otra informaci√≥n relevante para compras\n    \n    IMPORTANTE:\n    - Usa save_to_memory para guardar cada preferencia importante\n    - Guarda el contexto de cada preferencia\n    - Confirma la informaci√≥n con el usuario\n    - S√© proactivo: haz preguntas al usuario para obtener la informaci√≥n necesaria\n\n    Debes preguntarle al usuario que quiere haciendo preguntas y dandole ejemplos, debes ser proactivo para obtener la informacion del usuario\n\n    Una vez que terminas de recolectar las preferencias, debes preguntale al usuario sobre el tipo de compra que desea hacer:\n      * "¬øQu√© tipo de compra te gustar√≠a hacer hoy? Por ejemplo:\n         - ¬øCompra semanal completa?\n         - ¬øIngredientes para alguna receta espec√≠fica?\n         - ¬øProductos b√°sicos?\n         - ¬øAlgo espec√≠fico que necesites?"\n\n    ', 'role': 'system'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': '¬°Hola! Bienvenido a Frizbee, tu asistente para facilitar el proceso de compras en el supermercado Jumbo. Estoy aqu√≠ para ayudarte a recolectar tus preferencias de compra y hacer tu experiencia m√°s c√≥moda.\n\nPara comenzar, me gustar√≠a saber un poco m√°s sobre tus h√°bitos de compra. ¬øTienes alguna preferencia diet√©tica, como ser vegetariano o vegano?', 'role': 'assistant'}, {'content': 'hola', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': '¬°Hola de nuevo! Estoy aqu√≠ para ayudarte con tus preferencias de compra en el supermercado Jumbo. ¬øTe gustar√≠a contarme si tienes alguna dieta espec√≠fica que sigas, como vegetariano o vegano? Esto me ayudar√° a personalizar mejor tus recomendaciones.', 'role': 'assistant'}, {'content': '¬°Hola de nuevo! Parece que estamos un poco atrapados en un saludo. Estoy aqu√≠ para ayudarte con tus compras en Jumbo. \n\nComo asistente de Frizbee, me gustar√≠a saber m√°s sobre tus preferencias. ¬øTienes alguna dieta especial o restricciones alimentarias que debamos tener en cuenta?', 'role': 'assistant'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'ola', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'hola', 'role': 'user'}, {'content': 'soy vegan', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': '¬°Genial, gracias por compartirlo! He guardado que eres vegano. \n\nAhora, me gustar√≠a saber si tienes alguna alergia o restricci√≥n alimentaria que deba tener en cuenta al hacer tus recomendaciones. ¬øHay alg√∫n alimento espec√≠fico que debas evitar?', 'role': 'assistant'}, {'content': 'no me gusta la manzana', 'role': 'user'}, {'content': 'He guardado que no te gusta la manzana y que eres vegano. \n\nAhora, para entender mejor tus h√°bitos de compra, ¬øpuedes decirme cu√°ntas personas hay en tu familia o cu√°ntas compras sueles hacer? Esto me ayudar√° a sugerirte las cantidades adecuadas.', 'role': 'assistant'}, {'content': 'vivo con mi pareja', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': 'soy vegano', 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'type': 'function', 'id': 'call_4508FRkWTazMOe6Z3ehZ8XLr', 'function': {'name': 'save_to_memory', 'arguments': '{"user_id": "5491149276686", "content": "es vegano", "context": "Preferencia diet\\u00e9tica del usuario"}'}}, {'type': 'function', 'id': 'call_o6Ncuq2YsPCBsQrcf2syYDS0', 'function': {'name': 'save_to_memory', 'arguments': '{"user_id": "5491149276686", "content": "vive con su pareja", "context": "Informaci\\u00f3n sobre el tama\\u00f1o de la familia del usuario"}'}}]}, {'content': 'es vegano|Preferencia diet√©tica del usuario', 'role': 'tool', 'tool_call_id': 'call_4508FRkWTazMOe6Z3ehZ8XLr'}, {'content': 'vive con su pareja|Informaci√≥n sobre el tama√±o de la familia del usuario', 'role': 'tool', 'tool_call_id': 'call_o6Ncuq2YsPCBsQrcf2syYDS0'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7, 'tools': [{'type': 'function', 'function': {'name': 'save_to_memory', 'description': "Save important information about the user to AI's memory.\nArgs:\n    user_id: The user's ID (must be a valid UUID)\n    content: The information to remember (what the user said or preference)\n    context: Why this information is important or when it was mentioned", 'parameters': {'properties': {'user_id': {'type': 'string'}, 'content': {'type': 'string'}, 'context': {'type': 'string'}}, 'required': ['user_id', 'content', 'context'], 'type': 'object'}}}]}} [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:446]
2024-12-26 19:28:45,735 DEBUG: Sending HTTP Request: POST https://api.openai.com/v1/chat/completions [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:970]
2024-12-26 19:28:45,735 DEBUG: connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,758 DEBUG: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x128a6e8d0> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,758 DEBUG: start_tls.started ssl_context=<ssl.SSLContext object at 0x12894b770> server_hostname='api.openai.com' timeout=None [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,895 DEBUG: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x12925e750> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,895 DEBUG: send_request_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,895 DEBUG: send_request_headers.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,895 DEBUG: send_request_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,896 DEBUG: send_request_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:45,896 DEBUG: receive_response_headers.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:46,690 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 19:28:46,690 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 19:28:46,691 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkM2NUI3NDlCN0ZDQzI4NjY4MAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 19:28:46,695 INFO: 127.0.0.1 - - [26/Dec/2024 19:28:46] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:28:46,975 DEBUG: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 26 Dec 2024 22:28:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-lm32wg6n98ac7fn5g9zn5hht'), (b'openai-processing-ms', b'574'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'199096'), (b'x-ratelimit-reset-requests', b'46.165s'), (b'x-ratelimit-reset-tokens', b'271ms'), (b'x-request-id', b'req_37cc989e7e294ff222ddb0ca0bcf7562'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=bIn5T6tGBDpVIu2tHN6AfddfIrqiyGr9pcyw7JTD3jQ-1735252127-1.0.1.1-TAA.i3L7I0OXwHeNABvzFBylkV_tR8QLCDq99EWy7F1pqWWVOAtnoB6gsKFBnEowm2AHqmO0rgddr_egZblQAg; path=/; expires=Thu, 26-Dec-24 22:58:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=E2kp3821j0lpcp9.YgpuJwU8zl.N_gcUflfuHsBNWJY-1735252127303-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f84817d198d9c11-EZE'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:46,975 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:28:46,975 DEBUG: receive_response_body.started request=<Request [b'POST']> [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:46,976 DEBUG: receive_response_body.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:46,976 DEBUG: response_closed.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:46,976 DEBUG: response_closed.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:46,976 DEBUG: HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Thu, 26 Dec 2024 22:28:47 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-lm32wg6n98ac7fn5g9zn5hht'), ('openai-processing-ms', '574'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9994'), ('x-ratelimit-remaining-tokens', '199096'), ('x-ratelimit-reset-requests', '46.165s'), ('x-ratelimit-reset-tokens', '271ms'), ('x-request-id', 'req_37cc989e7e294ff222ddb0ca0bcf7562'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=bIn5T6tGBDpVIu2tHN6AfddfIrqiyGr9pcyw7JTD3jQ-1735252127-1.0.1.1-TAA.i3L7I0OXwHeNABvzFBylkV_tR8QLCDq99EWy7F1pqWWVOAtnoB6gsKFBnEowm2AHqmO0rgddr_egZblQAg; path=/; expires=Thu, 26-Dec-24 22:58:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=E2kp3821j0lpcp9.YgpuJwU8zl.N_gcUflfuHsBNWJY-1735252127303-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f84817d198d9c11-EZE'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')]) [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1009]
2024-12-26 19:28:46,976 DEBUG: request_id: req_37cc989e7e294ff222ddb0ca0bcf7562 [in /usr/local/lib/python3.11/site-packages/openai/_base_client.py:1017]
2024-12-26 19:28:47,361 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:28:47,362 INFO: 127.0.0.1 - - [26/Dec/2024 19:28:47] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:28:47,866 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:28:47,866 INFO: 127.0.0.1 - - [26/Dec/2024 19:28:47] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:28:48,052 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:28:48,053 INFO: 127.0.0.1 - - [26/Dec/2024 19:28:48] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:28:48,552 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 19:28:48,552 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 19:28:48,553 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjhCOEZBQjJDMDYzM0M1QzNGRgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 19:28:48,554 INFO: 127.0.0.1 - - [26/Dec/2024 19:28:48] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:28:49,107 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:28:49,107 INFO: 127.0.0.1 - - [26/Dec/2024 19:28:49] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:28:49,656 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:28:49,657 INFO: 127.0.0.1 - - [26/Dec/2024 19:28:49] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:28:49,772 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:28:49,773 INFO: 127.0.0.1 - - [26/Dec/2024 19:28:49] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:28:59,229 DEBUG: Closing Client.session [in /usr/local/lib/python3.11/site-packages/langsmith/client.py:332]
2024-12-26 19:28:59,230 DEBUG: Closing Client.session [in /usr/local/lib/python3.11/site-packages/langsmith/client.py:332]
2024-12-26 19:28:59,583 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:59,583 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:59,584 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:59,584 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:59,584 DEBUG: close.started [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:28:59,584 DEBUG: close.complete [in /usr/local/lib/python3.11/site-packages/httpcore/_trace.py:45]
2024-12-26 19:29:18,287 INFO: Flask app started [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/run.py:26]
2024-12-26 19:29:18,333 INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.186:8000 [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:29:18,334 INFO: [33mPress CTRL+C to quit[0m [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:29:40,194 INFO: Discovering subpackages in _NamespacePath(['/usr/local/lib/python3.11/site-packages/pinecone_plugins']) [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_namespace_packages.py:12]
2024-12-26 19:29:40,195 INFO: Looking for plugins in pinecone_plugins.inference [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_plugins.py:9]
2024-12-26 19:29:40,225 INFO: Installing plugin inference into Pinecone [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/installation.py:10]
2024-12-26 19:29:44,950 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:29:47,709 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:29:48,940 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:29:50,306 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 19:29:50,306 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 19:29:50,307 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjdFMkNDQUFCMDY4MDRFODY2QQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 19:29:50,308 INFO: 127.0.0.1 - - [26/Dec/2024 19:29:50] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:29:50,961 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:29:50,961 INFO: 127.0.0.1 - - [26/Dec/2024 19:29:50] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:29:51,498 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:29:51,498 INFO: 127.0.0.1 - - [26/Dec/2024 19:29:51] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:29:51,747 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:29:51,748 INFO: 127.0.0.1 - - [26/Dec/2024 19:29:51] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:30:02,091 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:30:03,692 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:30:05,019 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:30:06,861 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 19:30:06,862 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 19:30:06,862 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjkwOUM2N0MzRjY4QUYzOUIyMAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 19:30:06,863 INFO: 127.0.0.1 - - [26/Dec/2024 19:30:06] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:30:07,669 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:30:07,670 INFO: 127.0.0.1 - - [26/Dec/2024 19:30:07] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:30:08,046 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:30:08,047 INFO: 127.0.0.1 - - [26/Dec/2024 19:30:08] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:30:08,162 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:30:08,163 INFO: 127.0.0.1 - - [26/Dec/2024 19:30:08] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:30:32,639 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:30:34,877 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:30:36,454 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 19:30:36,455 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 19:30:36,455 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkQyQ0Q4NjBDQzczOUFCQzQ5QwA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 19:30:36,456 INFO: 127.0.0.1 - - [26/Dec/2024 19:30:36] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:30:36,933 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:30:36,934 INFO: 127.0.0.1 - - [26/Dec/2024 19:30:36] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:30:37,686 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:30:37,687 INFO: 127.0.0.1 - - [26/Dec/2024 19:30:37] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:30:37,689 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:30:37,690 INFO: 127.0.0.1 - - [26/Dec/2024 19:30:37] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:30:54,955 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:30:57,818 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:30:59,486 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 19:30:59,486 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 19:30:59,486 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkE4QjQxMzk2Q0MwQjYwQjY3QQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 19:30:59,487 INFO: 127.0.0.1 - - [26/Dec/2024 19:30:59] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:31:00,078 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:31:00,078 INFO: 127.0.0.1 - - [26/Dec/2024 19:31:00] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:31:00,516 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:31:00,517 INFO: 127.0.0.1 - - [26/Dec/2024 19:31:00] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:31:00,678 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:31:00,679 INFO: 127.0.0.1 - - [26/Dec/2024 19:31:00] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:31:13,088 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:19,668 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:20,520 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:20,571 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:20,577 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:20,581 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:20,670 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:20,690 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:20,813 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:20,873 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:20,907 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:20,931 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:20,939 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:20,954 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:20,998 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:21,006 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:21,008 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:21,046 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:21,114 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:21,431 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:21,432 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:37,224 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:47,181 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:31:49,152 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 19:31:49,152 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 19:31:49,152 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkY4RDBBOUM3OURBNjEyNTQ3MAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 19:31:49,154 INFO: 127.0.0.1 - - [26/Dec/2024 19:31:49] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:31:49,969 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:31:49,970 INFO: 127.0.0.1 - - [26/Dec/2024 19:31:49] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:31:50,256 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:31:50,257 INFO: 127.0.0.1 - - [26/Dec/2024 19:31:50] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:31:50,431 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:31:50,431 INFO: 127.0.0.1 - - [26/Dec/2024 19:31:50] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:35:33,376 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:35:35,483 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:35:36,728 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:35:39,154 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 19:35:39,154 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 19:35:39,154 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkY0ODUxRTczNjg5MUVGNDJEQgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 19:35:39,157 INFO: 127.0.0.1 - - [26/Dec/2024 19:35:39] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:35:39,946 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:35:39,947 INFO: 127.0.0.1 - - [26/Dec/2024 19:35:39] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:35:40,209 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:35:40,210 INFO: 127.0.0.1 - - [26/Dec/2024 19:35:40] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:35:40,601 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:35:40,602 INFO: 127.0.0.1 - - [26/Dec/2024 19:35:40] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:36:02,550 INFO: Flask app started [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/run.py:26]
2024-12-26 19:36:02,586 INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.186:8000 [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:36:02,587 INFO: [33mPress CTRL+C to quit[0m [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:36:26,102 INFO: Discovering subpackages in _NamespacePath(['/usr/local/lib/python3.11/site-packages/pinecone_plugins']) [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_namespace_packages.py:12]
2024-12-26 19:36:26,104 INFO: Looking for plugins in pinecone_plugins.inference [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_plugins.py:9]
2024-12-26 19:36:26,134 INFO: Installing plugin inference into Pinecone [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/installation.py:10]
2024-12-26 19:36:31,452 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:36:33,305 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 19:36:33,305 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 19:36:33,305 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjBCRTEyQUQ1QTUxQ0REMjdGQwA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 19:36:33,307 INFO: 127.0.0.1 - - [26/Dec/2024 19:36:33] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:36:34,043 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:36:34,044 INFO: 127.0.0.1 - - [26/Dec/2024 19:36:34] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:36:34,480 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:36:34,481 INFO: 127.0.0.1 - - [26/Dec/2024 19:36:34] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:36:34,504 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:36:34,504 INFO: 127.0.0.1 - - [26/Dec/2024 19:36:34] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:37:00,969 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:37:02,391 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 19:37:02,392 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 19:37:02,392 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjFENUYwREVBREQ3RkQ0RjM2RQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 19:37:02,393 INFO: 127.0.0.1 - - [26/Dec/2024 19:37:02] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:37:03,061 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:37:03,062 INFO: 127.0.0.1 - - [26/Dec/2024 19:37:03] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:37:03,808 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:37:03,809 INFO: 127.0.0.1 - - [26/Dec/2024 19:37:03] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:37:03,918 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:37:03,919 INFO: 127.0.0.1 - - [26/Dec/2024 19:37:03] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:42:36,732 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 19:42:38,133 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 19:42:38,133 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 19:42:38,133 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkM2NTJGOTQ5RTlDQkQ2MkIzQgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 19:42:38,139 INFO: 127.0.0.1 - - [26/Dec/2024 19:42:38] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:42:38,843 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:42:38,843 INFO: 127.0.0.1 - - [26/Dec/2024 19:42:38] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:42:39,152 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:42:39,153 INFO: 127.0.0.1 - - [26/Dec/2024 19:42:39] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 19:42:39,529 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 19:42:39,530 INFO: 127.0.0.1 - - [26/Dec/2024 19:42:39] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:17:17,570 INFO: Flask app started [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/run.py:26]
2024-12-26 20:17:17,651 INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.186:8000 [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:17:17,651 INFO: [33mPress CTRL+C to quit[0m [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:17:39,458 INFO: Discovering subpackages in _NamespacePath(['/usr/local/lib/python3.11/site-packages/pinecone_plugins']) [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_namespace_packages.py:12]
2024-12-26 20:17:39,459 INFO: Looking for plugins in pinecone_plugins.inference [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_plugins.py:9]
2024-12-26 20:17:39,489 INFO: Installing plugin inference into Pinecone [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/installation.py:10]
2024-12-26 20:17:48,918 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:17:49,730 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:17:49,780 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:17:49,785 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:17:49,797 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:17:49,810 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:17:49,812 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:17:49,813 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:17:49,883 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:17:49,892 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:17:50,031 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:17:50,063 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:17:50,107 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:17:50,166 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:17:50,192 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:17:50,456 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:03,122 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:03,555 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:03,564 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:03,569 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:03,574 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:03,586 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:03,592 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:03,608 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:03,645 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:03,744 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:03,840 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:03,842 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:03,897 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:03,915 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:03,917 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:03,964 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:09,367 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:15,044 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:16,757 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:18:16,757 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:18:16,758 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjI2MDJGQjNDOEEwQTQzMTk3MQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:18:16,759 INFO: 127.0.0.1 - - [26/Dec/2024 20:18:16] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:18:17,561 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:17,641 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:18:17,647 INFO: 127.0.0.1 - - [26/Dec/2024 20:18:17] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:18:17,780 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:18:17,780 INFO: 127.0.0.1 - - [26/Dec/2024 20:18:17] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:18:18,510 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:18:18,511 INFO: 127.0.0.1 - - [26/Dec/2024 20:18:18] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:18:23,298 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:24,215 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:25,549 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:18:25,550 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:18:25,550 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjkyMDRBQzA2Nzk0MTk0Q0M0RQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:18:25,551 INFO: 127.0.0.1 - - [26/Dec/2024 20:18:25] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:18:26,195 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:18:26,196 INFO: 127.0.0.1 - - [26/Dec/2024 20:18:26] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:18:26,393 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:18:26,393 INFO: 127.0.0.1 - - [26/Dec/2024 20:18:26] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:18:26,990 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:18:26,991 INFO: 127.0.0.1 - - [26/Dec/2024 20:18:26] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:18:35,686 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:41,402 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:18:42,853 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:18:42,854 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:18:42,854 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkFCNjM4MTEwNjc4RjU2MkY1MgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:18:42,855 INFO: 127.0.0.1 - - [26/Dec/2024 20:18:42] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:18:43,421 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:18:43,422 INFO: 127.0.0.1 - - [26/Dec/2024 20:18:43] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:18:44,018 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:18:44,018 INFO: 127.0.0.1 - - [26/Dec/2024 20:18:44] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:18:44,130 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:18:44,131 INFO: 127.0.0.1 - - [26/Dec/2024 20:18:44] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:21:45,056 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:21:46,389 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:21:46,829 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:21:48,962 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:21:55,601 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:21:57,023 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:21:57,024 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:21:57,024 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkY0QkVCOTgwMDNFQTdGOTMwRgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:21:57,027 INFO: 127.0.0.1 - - [26/Dec/2024 20:21:57] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:21:57,846 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:21:57,847 INFO: 127.0.0.1 - - [26/Dec/2024 20:21:57] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:21:58,027 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:21:58,028 INFO: 127.0.0.1 - - [26/Dec/2024 20:21:58] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:21:58,755 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:21:58,756 INFO: 127.0.0.1 - - [26/Dec/2024 20:21:58] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:22:57,471 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:23:05,633 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:23:11,360 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:23:12,821 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:23:12,822 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:23:12,822 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjE2QkQzOUFCMjJBNThFN0JDOAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:23:12,823 INFO: 127.0.0.1 - - [26/Dec/2024 20:23:12] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:23:13,566 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:23:13,566 INFO: 127.0.0.1 - - [26/Dec/2024 20:23:13] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:23:14,222 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:23:14,222 INFO: 127.0.0.1 - - [26/Dec/2024 20:23:14] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:23:20,954 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:23:20,954 INFO: 127.0.0.1 - - [26/Dec/2024 20:23:20] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:23:21,616 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:23:21,617 INFO: 127.0.0.1 - - [26/Dec/2024 20:23:21] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:29:44,873 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:29:51,307 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:29:52,914 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:29:52,914 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:29:52,914 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjRDRjI2MjE4QTA5MEI4MzExMAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:29:52,915 INFO: 127.0.0.1 - - [26/Dec/2024 20:29:52] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:29:53,562 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:29:53,563 INFO: 127.0.0.1 - - [26/Dec/2024 20:29:53] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:29:54,252 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:29:54,253 INFO: 127.0.0.1 - - [26/Dec/2024 20:29:54] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:29:54,491 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:29:54,491 INFO: 127.0.0.1 - - [26/Dec/2024 20:29:54] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:30:25,058 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:30:36,403 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:30:37,978 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:30:37,979 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:30:37,979 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjgzRkQ4M0U1NEVEQkM4ODc4OQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:30:37,981 INFO: 127.0.0.1 - - [26/Dec/2024 20:30:37] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:30:38,770 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:30:38,772 INFO: 127.0.0.1 - - [26/Dec/2024 20:30:38] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:30:39,176 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:30:39,177 INFO: 127.0.0.1 - - [26/Dec/2024 20:30:39] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:30:39,517 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:30:39,518 INFO: 127.0.0.1 - - [26/Dec/2024 20:30:39] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:34:27,299 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:34:33,372 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:34:35,607 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:34:35,607 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:34:35,608 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjM5RjY2MDE5ODdGN0Y3MUY2NgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:34:35,609 INFO: 127.0.0.1 - - [26/Dec/2024 20:34:35] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:34:36,478 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:34:36,479 INFO: 127.0.0.1 - - [26/Dec/2024 20:34:36] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:34:36,907 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:34:36,908 INFO: 127.0.0.1 - - [26/Dec/2024 20:34:36] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:34:37,206 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:34:37,207 INFO: 127.0.0.1 - - [26/Dec/2024 20:34:37] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:34:52,479 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:34:53,728 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:34:55,217 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:34:55,217 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:34:55,217 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjgyNzMwODIyQzQ3RTA3NzA4RAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:34:55,218 INFO: 127.0.0.1 - - [26/Dec/2024 20:34:55] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:34:56,037 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:34:56,038 INFO: 127.0.0.1 - - [26/Dec/2024 20:34:56] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:34:56,139 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:34:56,140 INFO: 127.0.0.1 - - [26/Dec/2024 20:34:56] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:34:56,533 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:34:56,534 INFO: 127.0.0.1 - - [26/Dec/2024 20:34:56] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:35:22,235 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:35:27,103 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:35:28,575 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:35:28,575 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:35:28,576 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjg0OTQ4NzNEQTkzMDFGQjYwQwA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:35:28,579 INFO: 127.0.0.1 - - [26/Dec/2024 20:35:28] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:35:29,151 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:35:29,152 INFO: 127.0.0.1 - - [26/Dec/2024 20:35:29] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:35:29,661 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:35:29,663 INFO: 127.0.0.1 - - [26/Dec/2024 20:35:29] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:35:29,778 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:35:29,779 INFO: 127.0.0.1 - - [26/Dec/2024 20:35:29] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:35:47,699 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:35:56,658 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:35:58,189 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:35:58,189 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:35:58,189 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjQyQjY1MUNDNzZBRERGMUU2NwA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:35:58,190 INFO: 127.0.0.1 - - [26/Dec/2024 20:35:58] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:35:59,203 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:35:59,204 INFO: 127.0.0.1 - - [26/Dec/2024 20:35:59] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:35:59,312 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:35:59,313 INFO: 127.0.0.1 - - [26/Dec/2024 20:35:59] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:35:59,659 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:35:59,659 INFO: 127.0.0.1 - - [26/Dec/2024 20:35:59] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:36:51,364 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:36:52,708 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:36:53,491 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:36:58,154 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:36:59,598 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:36:59,598 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:36:59,599 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjM2QzY4QUI2NURGREM4N0Y0QgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:36:59,600 INFO: 127.0.0.1 - - [26/Dec/2024 20:36:59] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:37:00,409 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:37:00,409 INFO: 127.0.0.1 - - [26/Dec/2024 20:37:00] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:37:00,654 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:37:00,655 INFO: 127.0.0.1 - - [26/Dec/2024 20:37:00] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:37:00,802 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:37:00,803 INFO: 127.0.0.1 - - [26/Dec/2024 20:37:00] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:38:02,198 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:38:04,461 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:38:04,849 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:38:10,201 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:38:12,076 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:38:12,076 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:38:12,076 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkI5M0RDRTAzMjA4NTVDNjY5QQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:38:12,079 INFO: 127.0.0.1 - - [26/Dec/2024 20:38:12] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:38:13,036 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:38:13,037 INFO: 127.0.0.1 - - [26/Dec/2024 20:38:13] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:38:13,334 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:38:13,335 INFO: 127.0.0.1 - - [26/Dec/2024 20:38:13] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:38:13,525 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:38:13,526 INFO: 127.0.0.1 - - [26/Dec/2024 20:38:13] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:38:35,468 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:38:36,480 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:38:37,310 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:38:40,527 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:38:42,337 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:38:42,337 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:38:42,337 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkNDMEQ1MUUyREI1NjAxRjAxMgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:38:42,338 INFO: 127.0.0.1 - - [26/Dec/2024 20:38:42] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:38:43,067 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:38:43,068 INFO: 127.0.0.1 - - [26/Dec/2024 20:38:43] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:38:43,500 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:38:43,500 INFO: 127.0.0.1 - - [26/Dec/2024 20:38:43] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:38:43,782 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:38:43,782 INFO: 127.0.0.1 - - [26/Dec/2024 20:38:43] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:39:04,766 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:39:07,087 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:39:12,694 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:39:14,038 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:39:14,038 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:39:14,039 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjQxMEIwMEMwOTE2RDVCQURGMwA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:39:14,040 INFO: 127.0.0.1 - - [26/Dec/2024 20:39:14] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:39:14,815 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:39:14,816 INFO: 127.0.0.1 - - [26/Dec/2024 20:39:14] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:39:15,116 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:39:15,117 INFO: 127.0.0.1 - - [26/Dec/2024 20:39:15] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:39:15,373 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:39:15,374 INFO: 127.0.0.1 - - [26/Dec/2024 20:39:15] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:39:35,382 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:39:37,001 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:39:37,522 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:39:44,038 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:39:45,446 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:39:45,446 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:39:45,446 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjk1QUNBQzZBRDMwRTQwNkQyQQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:39:45,452 INFO: 127.0.0.1 - - [26/Dec/2024 20:39:45] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:39:46,182 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:39:46,182 INFO: 127.0.0.1 - - [26/Dec/2024 20:39:46] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:39:46,358 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:39:46,358 INFO: 127.0.0.1 - - [26/Dec/2024 20:39:46] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:39:47,058 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:39:47,058 INFO: 127.0.0.1 - - [26/Dec/2024 20:39:47] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:39:52,747 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:39:54,549 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:39:56,088 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:39:56,089 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:39:56,089 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkRCOEYzNUE4ODY2RDg0MUYzMQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:39:56,090 INFO: 127.0.0.1 - - [26/Dec/2024 20:39:56] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:39:57,002 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:39:57,003 INFO: 127.0.0.1 - - [26/Dec/2024 20:39:57] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:39:57,095 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:39:57,096 INFO: 127.0.0.1 - - [26/Dec/2024 20:39:57] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:39:57,675 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:39:57,675 INFO: 127.0.0.1 - - [26/Dec/2024 20:39:57] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:41:38,737 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:41:41,382 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:41:41,915 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:41:49,238 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:41:51,196 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:41:51,196 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:41:51,196 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjM3NjlCMUM2MkYxREIwNkFERAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:41:51,197 INFO: 127.0.0.1 - - [26/Dec/2024 20:41:51] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:41:52,042 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:41:52,042 INFO: 127.0.0.1 - - [26/Dec/2024 20:41:52] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:41:52,191 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:41:52,191 INFO: 127.0.0.1 - - [26/Dec/2024 20:41:52] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:41:52,603 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:41:52,604 INFO: 127.0.0.1 - - [26/Dec/2024 20:41:52] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:43:06,914 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:43:14,121 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:43:15,609 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:43:15,609 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:43:15,609 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjY2ODk4NzQzMDU5RkUwRjY3OAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:43:15,611 INFO: 127.0.0.1 - - [26/Dec/2024 20:43:15] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:43:16,204 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:43:16,204 INFO: 127.0.0.1 - - [26/Dec/2024 20:43:16] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:43:16,748 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:43:16,749 INFO: 127.0.0.1 - - [26/Dec/2024 20:43:16] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:43:16,877 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:43:16,878 INFO: 127.0.0.1 - - [26/Dec/2024 20:43:16] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:43:25,589 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:43:28,001 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:43:29,720 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:43:32,919 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:43:34,359 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:43:34,359 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:43:34,359 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjVGN0YwMUNDMzYyRDhCQzhBMAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:43:34,361 INFO: 127.0.0.1 - - [26/Dec/2024 20:43:34] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:43:35,093 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:43:35,094 INFO: 127.0.0.1 - - [26/Dec/2024 20:43:35] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:43:35,364 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:43:35,365 INFO: 127.0.0.1 - - [26/Dec/2024 20:43:35] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:43:35,582 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:43:35,583 INFO: 127.0.0.1 - - [26/Dec/2024 20:43:35] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:44:19,509 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:44:21,360 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:44:21,851 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:44:25,605 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:44:26,918 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:44:26,919 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:44:26,919 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkZDMjg4RDAxOEEwRUFEMjExRQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:44:26,920 INFO: 127.0.0.1 - - [26/Dec/2024 20:44:26] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:44:27,774 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:44:27,776 INFO: 127.0.0.1 - - [26/Dec/2024 20:44:27] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:44:27,978 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:44:27,979 INFO: 127.0.0.1 - - [26/Dec/2024 20:44:27] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:44:28,235 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:44:28,235 INFO: 127.0.0.1 - - [26/Dec/2024 20:44:28] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:44:52,639 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:44:54,632 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:44:56,332 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:44:56,333 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:44:56,333 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjJFQjE3MUVGQjU3OTZFQkFCMwA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:44:56,334 INFO: 127.0.0.1 - - [26/Dec/2024 20:44:56] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:44:56,991 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:44:56,992 INFO: 127.0.0.1 - - [26/Dec/2024 20:44:56] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:44:57,367 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:44:57,367 INFO: 127.0.0.1 - - [26/Dec/2024 20:44:57] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:44:57,848 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:44:57,849 INFO: 127.0.0.1 - - [26/Dec/2024 20:44:57] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:45:01,084 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:45:06,883 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:45:08,568 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:45:08,569 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:45:08,569 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkQyOENGNjE4MTI2QjZFN0RFOQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:45:08,570 INFO: 127.0.0.1 - - [26/Dec/2024 20:45:08] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:45:09,403 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:45:09,404 INFO: 127.0.0.1 - - [26/Dec/2024 20:45:09] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:45:09,477 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:45:09,478 INFO: 127.0.0.1 - - [26/Dec/2024 20:45:09] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:45:09,780 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:45:09,781 INFO: 127.0.0.1 - - [26/Dec/2024 20:45:09] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:45:30,071 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:45:32,895 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:45:41,711 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:45:43,071 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:45:43,071 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:45:43,072 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjhFREZBNjc0NjhGRkJENjFDRAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:45:43,073 INFO: 127.0.0.1 - - [26/Dec/2024 20:45:43] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:45:43,891 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:45:43,891 INFO: 127.0.0.1 - - [26/Dec/2024 20:45:43] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:45:44,102 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:45:44,103 INFO: 127.0.0.1 - - [26/Dec/2024 20:45:44] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:45:47,182 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:45:47,182 INFO: 127.0.0.1 - - [26/Dec/2024 20:45:47] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:47:21,410 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:47:24,021 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:47:24,539 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:47:24,875 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:47:31,306 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:47:32,673 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:47:32,673 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:47:32,674 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjA5QUE4NkEyNkQyNTBDNzFCNAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:47:32,678 INFO: 127.0.0.1 - - [26/Dec/2024 20:47:32] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:47:33,354 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:47:33,356 INFO: 127.0.0.1 - - [26/Dec/2024 20:47:33] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:47:33,642 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:47:33,643 INFO: 127.0.0.1 - - [26/Dec/2024 20:47:33] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:47:34,149 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:47:34,150 INFO: 127.0.0.1 - - [26/Dec/2024 20:47:34] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:48:02,515 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:48:05,575 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:48:12,423 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:48:14,472 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:48:14,472 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:48:14,473 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkZCNDlDOTgzMEQwNUIwMUVBRgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:48:14,474 INFO: 127.0.0.1 - - [26/Dec/2024 20:48:14] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:48:15,390 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:48:15,390 INFO: 127.0.0.1 - - [26/Dec/2024 20:48:15] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:48:15,519 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:48:15,520 INFO: 127.0.0.1 - - [26/Dec/2024 20:48:15] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:48:15,745 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:48:15,746 INFO: 127.0.0.1 - - [26/Dec/2024 20:48:15] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:48:31,862 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:48:34,664 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:48:36,609 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:48:39,231 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:48:39,231 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:48:39,231 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkNGQUQ0Mjg2RDgxNTJFNUM4NAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:48:39,232 INFO: 127.0.0.1 - - [26/Dec/2024 20:48:39] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:48:40,226 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:48:40,227 INFO: 127.0.0.1 - - [26/Dec/2024 20:48:40] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:48:40,257 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:48:40,259 INFO: 127.0.0.1 - - [26/Dec/2024 20:48:40] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:48:40,566 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:48:40,567 INFO: 127.0.0.1 - - [26/Dec/2024 20:48:40] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:52:52,770 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:52:54,639 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:52:54,639 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:52:54,639 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkI1REQ4NENFNjUwMTgzN0JERAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:52:54,641 INFO: 127.0.0.1 - - [26/Dec/2024 20:52:54] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:52:55,615 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:52:55,616 INFO: 127.0.0.1 - - [26/Dec/2024 20:52:55] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:52:55,949 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:52:55,950 INFO: 127.0.0.1 - - [26/Dec/2024 20:52:55] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:53:10,866 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 20:53:12,137 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 20:53:12,138 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 20:53:12,138 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjA2MDBCODlBRTY4M0M1OENERgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 20:53:12,139 INFO: 127.0.0.1 - - [26/Dec/2024 20:53:12] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:53:12,982 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:53:12,983 INFO: 127.0.0.1 - - [26/Dec/2024 20:53:12] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:53:13,204 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:53:13,205 INFO: 127.0.0.1 - - [26/Dec/2024 20:53:13] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:53:20,572 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:53:20,572 INFO: 127.0.0.1 - - [26/Dec/2024 20:53:20] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 20:53:20,573 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 20:53:20,574 INFO: 127.0.0.1 - - [26/Dec/2024 20:53:20] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:06:25,803 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 21:06:27,226 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 21:06:27,227 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 21:06:27,227 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkIxRTI5QjlDMkQwNENFNTE1MwA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 21:06:27,230 INFO: 127.0.0.1 - - [26/Dec/2024 21:06:27] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:06:28,073 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 21:06:28,074 INFO: 127.0.0.1 - - [26/Dec/2024 21:06:28] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:06:28,678 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 21:06:28,679 INFO: 127.0.0.1 - - [26/Dec/2024 21:06:28] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:08:36,676 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 21:08:36,678 INFO: 127.0.0.1 - - [26/Dec/2024 21:08:36] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:10:42,604 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 21:10:43,955 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 21:10:43,955 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 21:10:43,955 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkREQjI3QjY5N0EzRDY4NEQ2RQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 21:10:43,956 INFO: 127.0.0.1 - - [26/Dec/2024 21:10:43] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:10:44,998 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 21:10:44,999 INFO: 127.0.0.1 - - [26/Dec/2024 21:10:44] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:10:45,109 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 21:10:45,110 INFO: 127.0.0.1 - - [26/Dec/2024 21:10:45] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:15:11,693 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 21:15:11,698 INFO: 127.0.0.1 - - [26/Dec/2024 21:15:11] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:15:54,726 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 21:15:56,056 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 21:15:56,057 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 21:15:56,057 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjBFQTUyQzVFQjhGNzYxQkFERgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 21:15:56,058 INFO: 127.0.0.1 - - [26/Dec/2024 21:15:56] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:15:56,775 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 21:15:56,776 INFO: 127.0.0.1 - - [26/Dec/2024 21:15:56] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:15:57,287 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 21:15:57,288 INFO: 127.0.0.1 - - [26/Dec/2024 21:15:57] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:15:57,497 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 21:15:57,497 INFO: 127.0.0.1 - - [26/Dec/2024 21:15:57] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:16:29,130 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 21:16:31,180 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 21:16:31,180 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 21:16:31,181 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjBGMEUzRDcxQTUxNzBDMDJBMQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 21:16:31,182 INFO: 127.0.0.1 - - [26/Dec/2024 21:16:31] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:16:31,873 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 21:16:31,873 INFO: 127.0.0.1 - - [26/Dec/2024 21:16:31] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:16:32,412 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 21:16:32,413 INFO: 127.0.0.1 - - [26/Dec/2024 21:16:32] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:16:32,500 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 21:16:32,501 INFO: 127.0.0.1 - - [26/Dec/2024 21:16:32] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:16:37,321 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 21:16:38,619 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 21:16:38,619 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 21:16:38,619 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkFERjUyMEE1N0Q0MDJFMzE2MQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 21:16:38,621 INFO: 127.0.0.1 - - [26/Dec/2024 21:16:38] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:16:39,477 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 21:16:39,477 INFO: 127.0.0.1 - - [26/Dec/2024 21:16:39] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:16:39,699 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 21:16:39,700 INFO: 127.0.0.1 - - [26/Dec/2024 21:16:39] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 21:16:40,198 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 21:16:40,199 INFO: 127.0.0.1 - - [26/Dec/2024 21:16:40] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:26:40,422 ERROR: Exception on /webhook [POST] [in /usr/local/lib/python3.11/site-packages/flask/app.py:838]
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 1473, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 882, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 880, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/flask/app.py", line 865, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/decorators/security.py", line 36, in decorated_function
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 87, in webhook_post
    return handle_message()
           ^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py", line 44, in handle_message
    process_whatsapp_message(body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py", line 86, in process_whatsapp_message
    response = generate_response(message_body, wa_id, name)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/services/openai_service.py", line 37, in generate_response
    save_message(wa_id, "user", message_body)
  File "/Users/felipegoulu/projects/activos/jumbo_ai/backend/db.py", line 219, in save_message
    cur.execute("""
psycopg2.OperationalError: el servidor ha cerrado la conexi√≥n inesperadamente
	Probablemente se debe a que el servidor termin√≥ de manera anormal
	antes o durante el procesamiento de la petici√≥n.
el servidor ha cerrado la conexi√≥n inesperadamente
	Probablemente se debe a que el servidor termin√≥ de manera anormal
	antes o durante el procesamiento de la petici√≥n.

2024-12-26 22:26:40,482 INFO: 127.0.0.1 - - [26/Dec/2024 22:26:40] "[35m[1mPOST /webhook HTTP/1.1[0m" 500 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:26:50,123 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:26:51,784 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:26:51,784 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:26:51,784 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjA3QUM4MUM5NDY0Rjk4ODE0NAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:26:51,786 INFO: 127.0.0.1 - - [26/Dec/2024 22:26:51] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:26:52,536 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:26:52,538 INFO: 127.0.0.1 - - [26/Dec/2024 22:26:52] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:26:53,056 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:26:53,056 INFO: 127.0.0.1 - - [26/Dec/2024 22:26:53] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:26:53,154 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:26:53,154 INFO: 127.0.0.1 - - [26/Dec/2024 22:26:53] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:27:56,700 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:27:57,926 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:27:57,931 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:27:57,938 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:27:57,991 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:27:58,020 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:27:58,154 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:27:58,220 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:27:58,223 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:27:58,246 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:27:58,251 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:27:58,291 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:27:58,307 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:27:58,333 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:27:58,348 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:27:58,349 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:15,471 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:16,980 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:28:16,980 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:28:16,980 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjVGM0YzM0ZDRDBFOUYzMzExRgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:28:16,982 INFO: 127.0.0.1 - - [26/Dec/2024 22:28:16] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:28:17,916 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:28:17,916 INFO: 127.0.0.1 - - [26/Dec/2024 22:28:17] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:28:17,980 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:28:17,982 INFO: 127.0.0.1 - - [26/Dec/2024 22:28:17] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:28:20,057 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:20,328 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:28:20,328 INFO: 127.0.0.1 - - [26/Dec/2024 22:28:20] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:28:20,521 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:20,532 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:20,552 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:20,590 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:20,595 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:20,595 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:20,643 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:20,796 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:20,820 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:20,863 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:20,898 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:20,899 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:20,925 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:21,003 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:21,566 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:37,102 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:28:40,045 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:28:40,045 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:28:40,045 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjA1QTAzRTMyNUU4NTI3RDVBMgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:28:40,047 INFO: 127.0.0.1 - - [26/Dec/2024 22:28:40] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:28:40,781 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:28:40,782 INFO: 127.0.0.1 - - [26/Dec/2024 22:28:40] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:28:41,145 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:28:41,160 INFO: 127.0.0.1 - - [26/Dec/2024 22:28:41] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:28:41,774 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:28:41,774 INFO: 127.0.0.1 - - [26/Dec/2024 22:28:41] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:28:57,949 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:29:03,112 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:29:04,497 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:29:04,498 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:29:04,498 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjNCNkY3OTc1RUZFN0UxNERCNAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:29:04,500 INFO: 127.0.0.1 - - [26/Dec/2024 22:29:04] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:29:05,172 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:29:05,172 INFO: 127.0.0.1 - - [26/Dec/2024 22:29:05] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:29:05,399 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:29:05,400 INFO: 127.0.0.1 - - [26/Dec/2024 22:29:05] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:29:05,549 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:29:05,550 INFO: 127.0.0.1 - - [26/Dec/2024 22:29:05] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:29:07,043 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:29:20,844 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:29:33,554 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:29:35,152 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:29:35,152 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:29:35,152 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjFCRTNCOERDMDFGQTAxNTE3OQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:29:35,154 INFO: 127.0.0.1 - - [26/Dec/2024 22:29:35] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:29:35,927 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:29:35,928 INFO: 127.0.0.1 - - [26/Dec/2024 22:29:35] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:29:36,348 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:29:36,349 INFO: 127.0.0.1 - - [26/Dec/2024 22:29:36] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:29:38,568 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:29:38,569 INFO: 127.0.0.1 - - [26/Dec/2024 22:29:38] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:29:58,285 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:30:14,647 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:30:21,028 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:30:22,557 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:30:22,559 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:30:22,559 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkExMjU3NEJCQTg2MjY2QUM5RgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:30:22,563 INFO: 127.0.0.1 - - [26/Dec/2024 22:30:22] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:30:23,354 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:30:23,354 INFO: 127.0.0.1 - - [26/Dec/2024 22:30:23] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:30:23,535 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:30:23,535 INFO: 127.0.0.1 - - [26/Dec/2024 22:30:23] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:30:29,648 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:30:36,197 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:30:37,504 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:30:37,505 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:30:37,505 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkQyRDRBREVFRDI2NDM1MzlBMgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:30:37,506 INFO: 127.0.0.1 - - [26/Dec/2024 22:30:37] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:30:38,259 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:30:38,260 INFO: 127.0.0.1 - - [26/Dec/2024 22:30:38] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:30:38,550 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:30:38,551 INFO: 127.0.0.1 - - [26/Dec/2024 22:30:38] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:31:06,788 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:31:06,790 INFO: 127.0.0.1 - - [26/Dec/2024 22:31:06] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:31:06,897 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:31:06,898 INFO: 127.0.0.1 - - [26/Dec/2024 22:31:06] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:36:23,812 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:36:29,952 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:36:31,449 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:36:31,450 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:36:31,450 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjc1RTUwNkIzNDFBRUEzOEVFNQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:36:31,453 INFO: 127.0.0.1 - - [26/Dec/2024 22:36:31] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:36:32,410 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:36:32,411 INFO: 127.0.0.1 - - [26/Dec/2024 22:36:32] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:36:32,616 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:36:32,617 INFO: 127.0.0.1 - - [26/Dec/2024 22:36:32] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:36:32,923 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:36:32,924 INFO: 127.0.0.1 - - [26/Dec/2024 22:36:32] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:37:08,873 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:37:10,816 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:37:12,232 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:37:14,463 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:37:14,463 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:37:14,463 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjlGRjdFMEYzMjREQUI4NzhGRQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:37:14,464 INFO: 127.0.0.1 - - [26/Dec/2024 22:37:14] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:37:15,181 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:37:15,182 INFO: 127.0.0.1 - - [26/Dec/2024 22:37:15] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:37:15,505 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:37:15,506 INFO: 127.0.0.1 - - [26/Dec/2024 22:37:15] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:37:29,315 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:37:29,316 INFO: 127.0.0.1 - - [26/Dec/2024 22:37:29] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:37:54,228 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:37:55,520 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:37:55,522 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:37:55,522 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjgzNkM0NERCMjQ5MTI4NDU2OAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:37:55,523 INFO: 127.0.0.1 - - [26/Dec/2024 22:37:55] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:37:56,587 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:37:56,588 INFO: 127.0.0.1 - - [26/Dec/2024 22:37:56] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:37:56,806 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:37:56,807 INFO: 127.0.0.1 - - [26/Dec/2024 22:37:56] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:37:56,808 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:37:56,809 INFO: 127.0.0.1 - - [26/Dec/2024 22:37:56] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:39:14,159 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:39:21,203 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:39:22,667 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:39:22,668 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:39:22,668 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkVDNEMxQzNEQ0QzQUFDRjEzNQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:39:22,671 INFO: 127.0.0.1 - - [26/Dec/2024 22:39:22] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:39:23,530 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:39:23,530 INFO: 127.0.0.1 - - [26/Dec/2024 22:39:23] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:39:23,566 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:39:23,567 INFO: 127.0.0.1 - - [26/Dec/2024 22:39:23] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:39:25,624 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:39:27,568 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:39:28,851 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:39:28,851 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:39:28,852 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjA5NTE2NkU3ODFDM0M2NDAzMQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:39:28,853 INFO: 127.0.0.1 - - [26/Dec/2024 22:39:28] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:39:29,776 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:39:29,777 INFO: 127.0.0.1 - - [26/Dec/2024 22:39:29] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:39:30,188 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:39:30,189 INFO: 127.0.0.1 - - [26/Dec/2024 22:39:30] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:44:47,107 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:44:47,112 INFO: 127.0.0.1 - - [26/Dec/2024 22:44:47] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:44:47,134 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:44:47,134 INFO: 127.0.0.1 - - [26/Dec/2024 22:44:47] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:46:40,016 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:46:42,330 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:46:43,755 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:46:43,755 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:46:43,755 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjkzNkIzODhFRTI4RDFCOEEyRgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:46:43,757 INFO: 127.0.0.1 - - [26/Dec/2024 22:46:43] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:46:44,678 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:46:44,678 INFO: 127.0.0.1 - - [26/Dec/2024 22:46:44] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:46:44,749 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:46:44,750 INFO: 127.0.0.1 - - [26/Dec/2024 22:46:44] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:48:01,208 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:48:01,212 INFO: 127.0.0.1 - - [26/Dec/2024 22:48:01] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:48:05,838 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:48:07,322 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:48:08,883 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:48:08,883 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:48:08,884 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjFENThDNkYxMzZDNDFBMkM0QQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:48:08,885 INFO: 127.0.0.1 - - [26/Dec/2024 22:48:08] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:48:09,782 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:48:09,782 INFO: 127.0.0.1 - - [26/Dec/2024 22:48:09] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:48:09,814 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:48:09,815 INFO: 127.0.0.1 - - [26/Dec/2024 22:48:09] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:48:19,644 INFO: Flask app started [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/run.py:26]
2024-12-26 22:48:19,706 INFO: [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:8000
 * Running on http://192.168.0.186:8000 [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:48:19,706 INFO: [33mPress CTRL+C to quit[0m [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:48:27,561 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:48:27,562 INFO: 127.0.0.1 - - [26/Dec/2024 22:48:27] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:48:39,664 INFO: Discovering subpackages in _NamespacePath(['/usr/local/lib/python3.11/site-packages/pinecone_plugins']) [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_namespace_packages.py:12]
2024-12-26 22:48:39,665 INFO: Looking for plugins in pinecone_plugins.inference [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/discover_plugins.py:9]
2024-12-26 22:48:39,699 INFO: Installing plugin inference into Pinecone [in /usr/local/lib/python3.11/site-packages/pinecone_plugin_interface/actions/installation.py:10]
2024-12-26 22:48:44,921 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:48:47,115 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:48:48,451 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:48:48,451 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:48:48,452 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkE4Q0ZDNEE1Q0VFOEEyRkI5MgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:48:48,453 INFO: 127.0.0.1 - - [26/Dec/2024 22:48:48] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:48:49,187 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:48:49,189 INFO: 127.0.0.1 - - [26/Dec/2024 22:48:49] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:48:49,392 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:48:49,392 INFO: 127.0.0.1 - - [26/Dec/2024 22:48:49] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:49:09,802 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:49:09,802 INFO: 127.0.0.1 - - [26/Dec/2024 22:49:09] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:49:19,511 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:49:21,112 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:49:22,586 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:49:22,586 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:49:22,587 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjU3MThBODFENjI1MzIxNEFEQQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:49:22,587 INFO: 127.0.0.1 - - [26/Dec/2024 22:49:22] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:49:23,267 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:49:23,284 INFO: 127.0.0.1 - - [26/Dec/2024 22:49:23] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:49:23,656 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:49:23,657 INFO: 127.0.0.1 - - [26/Dec/2024 22:49:23] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:49:38,051 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:49:38,051 INFO: 127.0.0.1 - - [26/Dec/2024 22:49:38] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:49:48,495 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:49:54,841 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:49:56,266 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:49:56,266 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:49:56,267 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjI3RkUzODdFRjczQkVFNzg2QgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:49:56,268 INFO: 127.0.0.1 - - [26/Dec/2024 22:49:56] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:49:56,994 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:49:56,995 INFO: 127.0.0.1 - - [26/Dec/2024 22:49:56] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:49:57,116 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:49:57,117 INFO: 127.0.0.1 - - [26/Dec/2024 22:49:57] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:50:04,472 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:50:04,472 INFO: 127.0.0.1 - - [26/Dec/2024 22:50:04] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:50:47,837 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:50:50,648 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:50:51,980 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:50:51,980 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:50:51,980 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkNCOEYyQ0RFNUM3OUVBMDk2MwA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:50:51,983 INFO: 127.0.0.1 - - [26/Dec/2024 22:50:51] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:50:52,908 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:50:52,909 INFO: 127.0.0.1 - - [26/Dec/2024 22:50:52] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:50:53,093 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:50:53,094 INFO: 127.0.0.1 - - [26/Dec/2024 22:50:53] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:50:59,055 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:50:59,057 INFO: 127.0.0.1 - - [26/Dec/2024 22:50:59] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:51:11,307 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:51:19,527 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:51:20,576 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:51:20,624 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:51:20,663 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:51:20,669 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:51:20,733 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:51:20,778 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:51:21,005 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:51:21,017 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:51:21,384 INFO: HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:51:32,124 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:51:33,519 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:51:33,519 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:51:33,519 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjg2NjkyOEFFOTBBNTBBRUFERAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:51:33,520 INFO: 127.0.0.1 - - [26/Dec/2024 22:51:33] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:51:34,207 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:51:34,208 INFO: 127.0.0.1 - - [26/Dec/2024 22:51:34] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:51:34,665 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:51:34,666 INFO: 127.0.0.1 - - [26/Dec/2024 22:51:34] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:51:36,036 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:51:52,705 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:51:58,220 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:51:59,594 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:51:59,594 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:51:59,594 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjVDQjczMTcxMzY5NzM0RTIwOQA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:51:59,596 INFO: 127.0.0.1 - - [26/Dec/2024 22:51:59] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:52:00,233 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:52:00,234 INFO: 127.0.0.1 - - [26/Dec/2024 22:52:00] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:52:00,782 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:52:00,783 INFO: 127.0.0.1 - - [26/Dec/2024 22:52:00] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:52:01,445 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:52:09,939 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:52:22,846 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:52:27,665 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:52:28,203 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:52:29,159 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:52:29,160 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:52:29,160 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEkUzOTVDRTIxMzRGNTYzMzA4MgA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:52:29,160 INFO: 127.0.0.1 - - [26/Dec/2024 22:52:29] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:52:29,891 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:52:29,891 INFO: 127.0.0.1 - - [26/Dec/2024 22:52:29] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:52:30,474 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:52:30,474 INFO: 127.0.0.1 - - [26/Dec/2024 22:52:30] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:52:35,518 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:52:35,518 INFO: 127.0.0.1 - - [26/Dec/2024 22:52:35] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:52:35,557 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:52:35,558 INFO: 127.0.0.1 - - [26/Dec/2024 22:52:35] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:52:35,676 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:52:35,677 INFO: 127.0.0.1 - - [26/Dec/2024 22:52:35] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:52:42,014 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:52:46,733 INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" [in /usr/local/lib/python3.11/site-packages/httpx/_client.py:1026]
2024-12-26 22:52:48,054 INFO: Status: 200 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:12]
2024-12-26 22:52:48,055 INFO: Content-type: application/json; charset=UTF-8 [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:13]
2024-12-26 22:52:48,055 INFO: Body: {"messaging_product":"whatsapp","contacts":[{"input":"+54111549276686","wa_id":"5491149276686"}],"messages":[{"id":"wamid.HBgNNTQ5MTE0OTI3NjY4NhUCABEYEjY2MDhBNjEyRDMwRkIxRUU5NAA="}]} [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/utils/whatsapp_utils.py:14]
2024-12-26 22:52:48,056 INFO: 127.0.0.1 - - [26/Dec/2024 22:52:48] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:52:49,084 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:52:49,085 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:52:49,085 INFO: 127.0.0.1 - - [26/Dec/2024 22:52:49] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:52:49,086 INFO: 127.0.0.1 - - [26/Dec/2024 22:52:49] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
2024-12-26 22:53:40,530 INFO: Received a WhatsApp status update. [in /Users/felipegoulu/projects/activos/jumbo_ai/whatsapp_front/app/views.py:39]
2024-12-26 22:53:40,554 INFO: 127.0.0.1 - - [26/Dec/2024 22:53:40] "POST /webhook HTTP/1.1" 200 - [in /usr/local/lib/python3.11/site-packages/werkzeug/_internal.py:97]
